{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[(0, 1.0), (1, 1.0), (2, 1.0)],\n",
    "           [(2, 1.0), (3, 1.0), (4, 1.0), (5, 1.0), (6, 1.0), (8, 1.0)],\n",
    "           [(1, 1.0), (3, 1.0), (4, 1.0), (7, 1.0)],\n",
    "           [(0, 1.0), (4, 2.0), (7, 1.0)],\n",
    "           [(3, 1.0), (5, 1.0), (6, 1.0)],\n",
    "           [(9, 1.0)],\n",
    "           [(9, 1.0), (10, 1.0)],\n",
    "           [(9, 1.0), (10, 1.0), (11, 1.0)],\n",
    "           [(8, 1.0), (10, 1.0), (11, 1.0)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.8075244024440723), (4, 0.5898341626740045)]\n"
     ]
    }
   ],
   "source": [
    "vec = [(0,1), (4,1)]\n",
    "print(tfidf[vec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index  = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4662244), (1, 0.19139354), (2, 0.2460055), (3, 0.82094586), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.0), (8, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[tfidf[vec]]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4662244 , 0.19139354, 0.2460055 , 0.82094586, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> import logging\n",
    ">>> logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> documents = [\"Human machine interface for lab abc computer applications\",\n",
    ">>>              \"A survey of user opinion of computer system response time\",\n",
    ">>>              \"The EPS user interface management system\",\n",
    ">>>              \"System and human system engineering testing of EPS\",\n",
    ">>>              \"Relation of user perceived response time to error measurement\",\n",
    ">>>              \"The generation of random binary unordered trees\",\n",
    ">>>              \"The intersection graph of paths in trees\",\n",
    ">>>              \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    ">>>              \"Graph minors A survey\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> # remove common words and tokenize\n",
    ">>> stoplist = set('for a of the and to in'.split())\n",
    ">>> texts = [[word for word in document.lower().split() if word not in stoplist]\n",
    ">>>          for document in documents]\n",
    ">>>\n",
    "\n",
    ">>> # remove words that appear only once\n",
    ">>> from collections import defaultdict\n",
    ">>> frequency = defaultdict(int)\n",
    "\n",
    ">>> for text in texts:\n",
    ">>>     for token in text:\n",
    ">>>         frequency[token] += 1\n",
    ">>>\n",
    "\n",
    ">>> texts = [[token for token in text if frequency[token] > 1]\n",
    ">>>          for text in texts]\n",
    ">>>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 00:36:05,700 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2018-10-07 00:36:05,702 : INFO : built Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...) from 9 documents (total 29 corpus positions)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 00:36:06,253 : INFO : saving Dictionary object under ./deerwester.dict, separately None\n",
      "2018-10-07 00:36:06,256 : INFO : saved ./deerwester.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(12 unique tokens: ['computer', 'human', 'interface', 'response', 'survey']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary.save('./deerwester.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'computer': 0, 'human': 1, 'interface': 2, 'response': 3, 'survey': 4, 'system': 5, 'time': 6, 'user': 7, 'eps': 8, 'trees': 9, 'graph': 10, 'minors': 11}\n"
     ]
    }
   ],
   "source": [
    "print(dictionary.token2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1)]\n"
     ]
    }
   ],
   "source": [
    "new_doc = \"Human computer interaction\"\n",
    "new_vec = dictionary.doc2bow(new_doc.lower().split())\n",
    "print(new_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 00:36:08,077 : INFO : storing corpus in Matrix Market format to ./deerwester.mm\n",
      "2018-10-07 00:36:08,079 : INFO : saving sparse matrix to ./deerwester.mm\n",
      "2018-10-07 00:36:08,081 : INFO : PROGRESS: saving document #0\n",
      "2018-10-07 00:36:08,083 : INFO : saved 9x12 matrix, density=25.926% (28/108)\n",
      "2018-10-07 00:36:08,084 : INFO : saving MmCorpus index to ./deerwester.mm.index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1)], [(0, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1)], [(2, 1), (5, 1), (7, 1), (8, 1)], [(1, 1), (5, 2), (8, 1)], [(3, 1), (6, 1), (7, 1)], [(9, 1)], [(9, 1), (10, 1)], [(9, 1), (10, 1), (11, 1)], [(4, 1), (10, 1), (11, 1)]]\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('./deerwester.mm', corpus) # store to disk for later use\n",
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus(object):\n",
    "    def __iter__(self):\n",
    "        for line in open('mycorpus.txt'):\n",
    "            # assume there's one doc per line, tokens sperated by whitespace\n",
    "            yield dictionary.doc2bow(line.lower().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyCorpus object at 0x7f5ab45f77f0>\n"
     ]
    }
   ],
   "source": [
    "corpus_mem_friendly = MyCorpus()\n",
    "print(corpus_mem_friendly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 01:04:47,366 : INFO : loading Dictionary object from ./deerwester.dict\n",
      "2018-10-07 01:04:47,369 : INFO : loaded ./deerwester.dict\n",
      "2018-10-07 01:04:47,371 : INFO : loaded corpus index from ./deerwester.mm.index\n",
      "2018-10-07 01:04:47,372 : INFO : initializing cython corpus reader from ./deerwester.mm\n",
      "2018-10-07 01:04:47,373 : INFO : accepted corpus with 9 documents, 12 features, 28 non-zero entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used files generated from first tutorial\n"
     ]
    }
   ],
   "source": [
    ">>> if (os.path.exists(\"./deerwester.dict\")):\n",
    ">>>    dictionary = corpora.Dictionary.load('./deerwester.dict')\n",
    ">>>    corpus = corpora.MmCorpus('./deerwester.mm')\n",
    ">>>    print(\"Used files generated from first tutorial\")\n",
    ">>> else:\n",
    ">>>    print(\"Please run first tutorial to generate data set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 01:59:54,096 : INFO : collecting document frequencies\n",
      "2018-10-07 01:59:54,097 : INFO : PROGRESS: processing document #0\n",
      "2018-10-07 01:59:54,098 : INFO : calculating IDF weights for 9 documents and 11 features (28 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "tfidf = models.TfidfModel(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 02:18:32,315 : INFO : using serial LSI version on this node\n",
      "2018-10-07 02:18:32,316 : INFO : updating model with new documents\n",
      "2018-10-07 02:18:32,318 : INFO : preparing a new chunk of documents\n",
      "2018-10-07 02:18:32,320 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-10-07 02:18:32,321 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2018-10-07 02:18:32,323 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2018-10-07 02:18:32,394 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2018-10-07 02:18:32,396 : INFO : computing the final decomposition\n",
      "2018-10-07 02:18:32,397 : INFO : keeping 2 factors (discarding 47.565% of energy spectrum)\n",
      "2018-10-07 02:18:32,398 : INFO : processed documents up to #9\n",
      "2018-10-07 02:18:32,462 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2018-10-07 02:18:32,463 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi[corpus_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 02:20:46,416 : INFO : topic #0(1.594): 0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"\n",
      "2018-10-07 02:20:46,417 : INFO : topic #1(1.476): -0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.703*\"trees\" + 0.538*\"graph\" + 0.402*\"minors\" + 0.187*\"survey\" + 0.061*\"system\" + 0.060*\"time\" + 0.060*\"response\" + 0.058*\"user\" + 0.049*\"computer\" + 0.035*\"interface\"'),\n",
       " (1,\n",
       "  '-0.460*\"system\" + -0.373*\"user\" + -0.332*\"eps\" + -0.328*\"interface\" + -0.320*\"time\" + -0.320*\"response\" + -0.293*\"computer\" + -0.280*\"human\" + -0.171*\"survey\" + 0.161*\"trees\"')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsi.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.06600783396090595), (1, -0.5200703306361845)]\n",
      "[(0, 0.19667592859142907), (1, -0.7609563167700042)]\n",
      "[(0, 0.08992639972446753), (1, -0.7241860626752505)]\n",
      "[(0, 0.07585847652178435), (1, -0.6320551586003422)]\n",
      "[(0, 0.10150299184980455), (1, -0.5737308483002956)]\n",
      "[(0, 0.7032108939378307), (1, 0.16115180214026148)]\n",
      "[(0, 0.8774787673119826), (1, 0.16758906864659842)]\n",
      "[(0, 0.9098624686818573), (1, 0.14086553628719448)]\n",
      "[(0, 0.6165825350569285), (1, -0.05392907566389098)]\n"
     ]
    }
   ],
   "source": [
    "for doc in corpus_lsi:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 02:24:08,896 : INFO : saving Projection object under ./model.lsi.projection, separately None\n",
      "2018-10-07 02:24:08,898 : INFO : saved ./model.lsi.projection\n",
      "2018-10-07 02:24:08,899 : INFO : saving LsiModel object under ./model.lsi, separately None\n",
      "2018-10-07 02:24:08,899 : INFO : not storing attribute projection\n",
      "2018-10-07 02:24:08,900 : INFO : not storing attribute dispatcher\n",
      "2018-10-07 02:24:08,901 : INFO : saved ./model.lsi\n",
      "2018-10-07 02:24:08,901 : INFO : loading LsiModel object from ./model.lsi\n",
      "2018-10-07 02:24:08,902 : INFO : loading id2word recursively from ./model.lsi.id2word.* with mmap=None\n",
      "2018-10-07 02:24:08,902 : INFO : setting ignored attribute projection to None\n",
      "2018-10-07 02:24:08,903 : INFO : setting ignored attribute dispatcher to None\n",
      "2018-10-07 02:24:08,903 : INFO : loaded ./model.lsi\n",
      "2018-10-07 02:24:08,903 : INFO : loading LsiModel object from ./model.lsi.projection\n",
      "2018-10-07 02:24:08,904 : INFO : loaded ./model.lsi.projection\n"
     ]
    }
   ],
   "source": [
    "lsi.save('./model.lsi')\n",
    "lsi = models.LsiModel.load('./model.lsi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 03:44:28,967 : INFO : using serial LSI version on this node\n",
      "2018-10-07 03:44:28,969 : INFO : updating model with new documents\n",
      "2018-10-07 03:44:28,970 : INFO : preparing a new chunk of documents\n",
      "2018-10-07 03:44:28,971 : INFO : using 100 extra samples and 2 power iterations\n",
      "2018-10-07 03:44:28,972 : INFO : 1st phase: constructing (12, 102) action matrix\n",
      "2018-10-07 03:44:28,973 : INFO : orthonormalizing (12, 102) action matrix\n",
      "2018-10-07 03:44:28,975 : INFO : 2nd phase: running dense svd on (12, 9) matrix\n",
      "2018-10-07 03:44:28,976 : INFO : computing the final decomposition\n",
      "2018-10-07 03:44:28,977 : INFO : keeping 2 factors (discarding 43.156% of energy spectrum)\n",
      "2018-10-07 03:44:28,977 : INFO : processed documents up to #9\n",
      "2018-10-07 03:44:28,978 : INFO : topic #0(3.341): 0.644*\"system\" + 0.404*\"user\" + 0.301*\"eps\" + 0.265*\"response\" + 0.265*\"time\" + 0.240*\"computer\" + 0.221*\"human\" + 0.206*\"survey\" + 0.198*\"interface\" + 0.036*\"graph\"\n",
      "2018-10-07 03:44:28,979 : INFO : topic #1(2.542): 0.623*\"graph\" + 0.490*\"trees\" + 0.451*\"minors\" + 0.274*\"survey\" + -0.167*\"system\" + -0.141*\"eps\" + -0.113*\"human\" + 0.107*\"time\" + 0.107*\"response\" + -0.072*\"interface\"\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus, id2word=dictionary, num_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.4618210045327155), (1, -0.07002766527899965)]\n"
     ]
    }
   ],
   "source": [
    "doc = \"Human computer interaction\"\n",
    "vec_bow = dictionary.doc2bow(doc.lower().split())\n",
    "vec_lsi = lsi[vec_bow] #convert the query to LSI space\n",
    "print(vec_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 03:48:11,057 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2018-10-07 03:48:11,058 : INFO : creating matrix with 9 documents and 2 features\n",
      "/home/omar/miniconda3/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(lsi[corpus]) #transform corpus to LSI space and index it... but I thought it was?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-07 03:50:04,890 : INFO : saving MatrixSimilarity object under ./deerwester.index, separately None\n",
      "2018-10-07 03:50:04,892 : INFO : saved ./deerwester.index\n",
      "2018-10-07 03:50:04,892 : INFO : loading MatrixSimilarity object from ./deerwester.index\n",
      "2018-10-07 03:50:04,893 : INFO : loaded ./deerwester.index\n"
     ]
    }
   ],
   "source": [
    "index.save('./deerwester.index')\n",
    "index = similarities.MatrixSimilarity.load('./deerwester.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.998093), (1, 0.93748635), (2, 0.9984453), (3, 0.9865886), (4, 0.90755945), (5, -0.12416792), (6, -0.10639259), (7, -0.09879464), (8, 0.050041765)]\n"
     ]
    }
   ],
   "source": [
    "sims = index[vec_lsi]\n",
    "print(list(enumerate(sims)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
