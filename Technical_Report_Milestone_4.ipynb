{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello there! My capstone project has to do with the field of Natural Language Programming (NLP) known as topic modeling (TM). ##\n",
    "\n",
    "It involves extracting the key words that summarize _what_ exactly a document is about, especially within the context of a larger corpus of documents.\n",
    "\n",
    "To this end, I am using the `gensim` library which specializes in efficient implementations of TM algorithms. Specifically, I will be using Latent Dirichlet Allocation (LDA), a popular model that generates _t_ discriminative topics based on assumptions about the number of topics and their distributions throughout the corpus.\n",
    "\n",
    "The corpus I am working with is from the `stat.ML` category of the [arXiv](https://arxiv.org/list/stat.ML/recent) database. I have about 18,000 paper abstracts covering a range of Machine Learning topics such as Optimization, Neural Network Architecture, and Applications to medical data.\n",
    "\n",
    "### Problem : ### \n",
    "**Within the context of an overarching topic, how can we extract more detailed subtopics and provide similar documents/recommendations effectively? (Secondary Problem) Can we use Dynamic Topic Modeling to show the papers that have been most influential in their fields?**\n",
    "\n",
    "### Data: ###\n",
    "**I used the same data I collected from Milestone #2 (with function arx_and_recreation()). I isolate just the abstracts (no date for now) in a Pandas Series or list**\n",
    "\n",
    "### Pre-Processing : ###\n",
    "\n",
    "I use a combination of \n",
    "    - regular expressions : strip extraneous punctuation/formatting/etc. \n",
    "    - English stop words : strip useless connecting words\n",
    "    - lemmatizers : combine variations of words (tense, pluaral) into one\n",
    "    - phrasers : common words that go together (like bigrams) are combined into one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text pre-processor:\n",
    "import re\n",
    "import gensim.parsing.preprocessing as genpre\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "lmtzr= WordNetLemmatizer()\n",
    "def prep_text(text):\n",
    "     #this regex removes LATEX formatting, numbers, citations, splits hyphens into two words\n",
    "    myreg=r'\\\\[\\w]+[\\{| ]|\\$[^\\$]+\\$|\\(.+\\, *\\d{2,4}\\w*\\)|\\S*\\/\\/\\S*|[\\\\.,\\/#!$%\\^&\\*;:{}=_`\\'\\\"~()><\\|]|\\[.+\\]|\\d+|\\b\\w{1,2}\\b'\n",
    "    parsed_data = text.replace('-', ' ')\n",
    "    parsed_data = re.sub(myreg, '', parsed_data)\n",
    "    parsed_data = [lmtzr.lemmatize(w) for w in parsed_data.lower().split() if w not in genpre.STOPWORDS]\n",
    "    if len(parsed_data) ==1: return parsed_data[0]\n",
    "    return parsed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having transformed all my abstracts from things that looked like this:\n",
    "```\n",
    "In this article, we derive concentration inequalities for the cross-validation estimate of the generalization error for empirical risk minimizers. In the general setting, we prove sanity-check bounds in the spirit of \\cite{KR99} \\textquotedblleft\\textit{bounds showing that the worst-case error of this estimate is not much worse that of training error estimate} \\textquotedblright . General loss functions and class of predictors with finite VC-dimension are considered. We closely follow the formalism introduced by \\cite{DUD03} to cover a large variety of cross-validation procedures including leave-one-out cross-validation, $k$% -fold cross-validation, hold-out cross-validation (or split sample), and the leave-$\\upsilon$-out cross-validation.   In particular, we focus on proving the consistency of the various cross-validation procedures. We point out the interest of each cross-validation procedure in terms of rate of convergence. An estimation curve with transition phases depending on the cross-validation procedure and not only on the percentage of observations in the test sample gives a simple rule on how to choose the cross-validation. An interesting consequence is that the size of the test sample is not required to grow to infinity for the consistency of the cross-validation procedure.\n",
    "```\n",
    "to this (it is not perfect but the odd strings that get thru the cracks are too rare to be of any effect):\n",
    "```\n",
    "['article', 'derive', 'concentration', 'inequality', 'cross', 'validation', 'estimate', 'generalization', 'error', 'empirical', 'risk', 'minimizers', 'general', 'setting', 'prove', 'sanity', 'check', 'bound', 'spirit', 'kr', 'textquotedblleftbounds', 'showing', 'worst', 'case', 'error', 'estimate', 'worse', 'training', 'error', 'estimate', 'general', 'loss', 'function', 'class', 'predictor', 'finite', 'dimension', 'considered', 'closely', 'follow', 'formalism', 'introduced', 'dud', 'cover', 'large', 'variety', 'cross', 'validation', 'procedure', 'including', 'leave', 'cross', 'validation', 'fold', 'cross', 'validation', 'hold', 'cross', 'validation', 'split', 'sample', 'leave', 'cross', 'validation', 'particular', 'focus', 'proving', 'consistency', 'cross', 'validation', 'procedure', 'point', 'cross', 'validation', 'procedure', 'term', 'rate', 'convergence', 'estimation', 'curve', 'transition', 'phase', 'depending', 'cross', 'validation', 'procedure', 'percentage', 'observation', 'test', 'sample', 'give', 'simple', 'rule', 'choose', 'cross', 'validation', 'interesting', 'consequence', 'size', 'test', 'sample', 'required', 'grow', 'infinity', 'consistency', 'cross', 'validation', 'procedure']\n",
    "```\n",
    "\n",
    "I am now in good position to conduct a topic analysis of my pre-processed text. I would like to do some Exploratory Data Analysis, too, to see what the distribution of my words are, etc. But first, let's examine the key gensim object with which we will be working:\n",
    "\n",
    "    - Corpus: this is the list of list of tokens/n_grams (a list such as above for every abstract)\n",
    "    - Dictionary: this assigns every unique token an id. It is used to look up id->token and token->id\n",
    "    - Bag Of Words (BoW): sums the total occurances of a token in a document (word ordering is not considered)\n",
    "    - LdaModel: uses the dictionary and BOW to generate a probablity distribution of topics across docs, and of words across topics\n",
    "    - Market Matrix: a more efficient way of storing th corpus, useful when calculating similarities between documents. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load up the relevant objects\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim import corpora, models, similarities\n",
    "from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel, TfidfModel\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "with open('./the_data_strikes_back/bigrams', 'rb') as fp:\n",
    "    corpus = pickle.load(fp)\n",
    "\n",
    "dictionary = corpora.Dictionary(corpus)\n",
    "bow = [dictionary.doc2bow(text) for text in corpus]\n",
    "\n",
    "# The gensim phraser I'm using\n",
    "bigrams = gensim.utils.SaveLoad.load('./the_data_strikes_back/bigram_phrases')\n",
    "#define the lda model\n",
    "model = LdaModel(bow, id2word=dictionary, num_topics=5)\n",
    "\n",
    "# Matrix representation of my corpus\n",
    "# corpora.MmCorpus.serialize('./the_data_strikes_back/full_bigram_corpus.mm', corpus)\n",
    "corp_matrix = corpora.MmCorpus('./the_data_strikes_back/full_bigram_corpus.mm')\n",
    "\n",
    "#The index of corp_matrix so that query lookup is efficient\n",
    "\n",
    "# index = similarities.MatrixSimilarity(corp_matrix)\n",
    "# index.save('./the_data_strikes_back/first_sim.index')\n",
    "# index = similarities.MatrixSimilarity.load('./the_data_strikes_back/first_sim.index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# let's look at the most common words throughout the corpus\n",
    "tot_counts = np.zeros(len(dictionary))\n",
    "\n",
    "# goes through the (id, count) tuples in every document and increments a total count\n",
    "for doc in bow:\n",
    "    for w in doc:\n",
    "        tot_counts[w[0]] += w[1]\n",
    "\n",
    "masterlist = [(dictionary[i], tot_counts[i]) for i in range(len(dictionary))]\n",
    "\n",
    "# the most common\n",
    "reference = sorted(masterlist, key=lambda w: w[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('model', 23446.0),\n",
       " ('method', 18755.0),\n",
       " ('algorithm', 17368.0),\n",
       " ('data', 16627.0),\n",
       " ('problem', 11707.0),\n",
       " ('based', 10494.0),\n",
       " ('approach', 10204.0),\n",
       " ('learning', 10175.0),\n",
       " ('network', 9262.0),\n",
       " ('result', 6774.0),\n",
       " ('proposed', 6144.0),\n",
       " ('performance', 5449.0),\n",
       " ('function', 5355.0),\n",
       " ('task', 5323.0),\n",
       " ('feature', 5292.0),\n",
       " ('training', 5115.0),\n",
       " ('new', 4544.0),\n",
       " ('distribution', 4486.0),\n",
       " ('framework', 4465.0),\n",
       " ('time', 4274.0),\n",
       " ('analysis', 4213.0),\n",
       " ('propose', 4209.0),\n",
       " ('set', 4189.0),\n",
       " ('graph', 4099.0),\n",
       " ('parameter', 4080.0),\n",
       " ('structure', 3949.0),\n",
       " ('sample', 3943.0),\n",
       " ('paper', 3940.0),\n",
       " ('number', 3923.0),\n",
       " ('use', 3845.0),\n",
       " ('information', 3831.0),\n",
       " ('application', 3830.0),\n",
       " ('different', 3826.0),\n",
       " ('technique', 3822.0),\n",
       " ('study', 3782.0),\n",
       " ('work', 3529.0),\n",
       " ('class', 3449.0),\n",
       " ('classification', 3429.0),\n",
       " ('machine_learning', 3417.0),\n",
       " ('matrix', 3377.0),\n",
       " ('prediction', 3211.0),\n",
       " ('provide', 3068.0),\n",
       " ('representation', 3051.0),\n",
       " ('kernel', 3035.0),\n",
       " ('setting', 2946.0),\n",
       " ('space', 2937.0),\n",
       " ('present', 2931.0),\n",
       " ('case', 2893.0),\n",
       " ('sparse', 2866.0),\n",
       " ('process', 2840.0),\n",
       " ('inference', 2816.0),\n",
       " ('datasets', 2710.0),\n",
       " ('large', 2647.0),\n",
       " ('given', 2634.0),\n",
       " ('neural_network', 2618.0),\n",
       " ('demonstrate', 2606.0),\n",
       " ('existing', 2584.0),\n",
       " ('estimation', 2581.0),\n",
       " ('image', 2579.0),\n",
       " ('accuracy', 2524.0),\n",
       " ('linear', 2520.0),\n",
       " ('estimate', 2507.0),\n",
       " ('point', 2428.0),\n",
       " ('efficient', 2402.0),\n",
       " ('input', 2373.0),\n",
       " ('regression', 2366.0),\n",
       " ('classifier', 2360.0),\n",
       " ('optimization', 2352.0),\n",
       " ('variable', 2352.0),\n",
       " ('novel', 2343.0),\n",
       " ('clustering', 2332.0),\n",
       " ('approximation', 2327.0),\n",
       " ('state_art', 2312.0),\n",
       " ('solution', 2257.0),\n",
       " ('general', 2248.0),\n",
       " ('order', 2225.0),\n",
       " ('error', 2213.0),\n",
       " ('multiple', 2199.0),\n",
       " ('example', 2186.0),\n",
       " ('statistical', 2172.0),\n",
       " ('experiment', 2171.0),\n",
       " ('bayesian', 2142.0),\n",
       " ('known', 2134.0),\n",
       " ('test', 2130.0),\n",
       " ('bound', 2074.0),\n",
       " ('estimator', 2012.0),\n",
       " ('simple', 1997.0),\n",
       " ('term', 1996.0),\n",
       " ('learn', 1978.0),\n",
       " ('property', 1963.0),\n",
       " ('particular', 1938.0),\n",
       " ('high_dimensional', 1917.0),\n",
       " ('optimal', 1909.0),\n",
       " ('dataset', 1904.0),\n",
       " ('value', 1891.0),\n",
       " ('vector', 1888.0),\n",
       " ('standard', 1875.0),\n",
       " ('measure', 1821.0),\n",
       " ('gradient', 1820.0),\n",
       " ('domain', 1791.0),\n",
       " ('allows', 1775.0),\n",
       " ('prior', 1744.0),\n",
       " ('signal', 1732.0),\n",
       " ('procedure', 1729.0),\n",
       " ('dynamic', 1723.0),\n",
       " ('random', 1711.0),\n",
       " ('step', 1703.0),\n",
       " ('state', 1703.0),\n",
       " ('deep_learning', 1693.0),\n",
       " ('label', 1676.0),\n",
       " ('node', 1669.0),\n",
       " ('important', 1665.0),\n",
       " ('deep', 1659.0),\n",
       " ('observation', 1653.0),\n",
       " ('rate', 1653.0),\n",
       " ('including', 1653.0),\n",
       " ('stochastic', 1649.0),\n",
       " ('complex', 1625.0),\n",
       " ('system', 1608.0),\n",
       " ('type', 1607.0),\n",
       " ('user', 1606.0),\n",
       " ('data_set', 1603.0),\n",
       " ('condition', 1602.0),\n",
       " ('real', 1584.0),\n",
       " ('design', 1581.0),\n",
       " ('single', 1580.0),\n",
       " ('sampling', 1568.0),\n",
       " ('noise', 1567.0),\n",
       " ('complexity', 1559.0),\n",
       " ('way', 1540.0),\n",
       " ('real_world', 1533.0),\n",
       " ('architecture', 1523.0),\n",
       " ('robust', 1521.0),\n",
       " ('applied', 1517.0),\n",
       " ('called', 1516.0),\n",
       " ('introduce', 1516.0),\n",
       " ('theory', 1508.0),\n",
       " ('cluster', 1502.0),\n",
       " ('consider', 1484.0),\n",
       " ('high', 1484.0),\n",
       " ('online', 1481.0),\n",
       " ('provides', 1469.0),\n",
       " ('strategy', 1453.0),\n",
       " ('better', 1445.0),\n",
       " ('mean', 1444.0),\n",
       " ('size', 1441.0),\n",
       " ('policy', 1441.0),\n",
       " ('modeling', 1412.0),\n",
       " ('develop', 1411.0),\n",
       " ('prove', 1406.0)]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference[:150]\n",
    "# we can see in just these top 15 there is a steep fall-off in descending term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25533"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ref for ref in reference if ref[1] <=10])\n",
    "# In contrast, there are around 25K words that occur 10 times or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "max_ammt = (18/10)*1000 # set this to 25000 to see the whole thing\n",
    "prevalent_counts = [ref[1] for ref in reference if ref[1] <= max_ammt] \n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.hist(prevalent_counts, bins=100);\n",
    "# plt.xlim(0, 5000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**By visually inspecting this historgram of word terms, we can see that it is probably a good idea to filter the extreme terms. Words like \"model, algorithm\" on the high end, or \"solomonoff\" and \"bssd\" (which only appear twice) do not contribute to our understanding of a topic. We should instead use the central mass of our distribution as our words. Luckily, gensim makes it easy to do this**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to figure out approx. how many words occur more than 1800 times (10% of docs, assuming it is a common ML term and not something special)\n",
    "max_total = (1/6) # the maximum document frequency I'd like -I'm going to set it roughly equal to 1/num_topics so I can get better overlap\n",
    "ref_cutoff = len([ref for ref in reference if ref[1] > len(corpus)*max_total])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(corpus)\n",
    "dictionary.filter_extremes(no_below=50) # remove terms that occur <50 times\n",
    "high_tokens = [dictionary.token2id[reference[i][0]] for i in range(ref_cutoff)] # ids of tokens that'll be excised\n",
    "dictionary.filter_tokens(bad_ids=high_tokens) # our 97 most common term ids, approximating words that occur more than once/10 documents\n",
    "# dictionary.filter_n_most_frequent(97) #doesn't work as expected...darn\n",
    "filtered_corp = [[w for w in doc if w in dictionary.token2id] for doc in corpus]\n",
    "filterd_bow = [dictionary.doc2bow(doc) for doc in filtered_corp]\n",
    "\n",
    "# now let's check our distributions again\n",
    "# let's look at the most common words throughout the corpus\n",
    "new_tot_counts = np.zeros(len(dictionary))\n",
    "\n",
    "# goes through the (id, count) tuples in every document and increments a total count\n",
    "for doc in filterd_bow:\n",
    "    for w in doc:\n",
    "        new_tot_counts[w[0]] += w[1]\n",
    "\n",
    "new_masterlist = [(dictionary[i], new_tot_counts[i]) for i in range(len(dictionary))]\n",
    "\n",
    "# the most common\n",
    "new_reference = sorted(new_masterlist, key=lambda w: w[1], reverse=True)\n",
    "\n",
    "new_prevalent_counts = [ref[1] for ref in new_reference]\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.hist(new_prevalent_counts, bins=100);\n",
    "# plt.xlim(0, 5000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(level= logging.CRITICAL)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.012*\"estimator\" + 0.011*\"estimate\" + 0.011*\"error\" + 0.009*\"regression\" + 0.009*\"estimation\" + 0.006*\"bayesian\" + 0.006*\"classifier\" + 0.006*\"statistical\" + 0.006*\"selection\" + 0.006*\"high_dimensional\"'),\n",
       " (1,\n",
       "  '0.013*\"neural_network\" + 0.010*\"deep_learning\" + 0.008*\"architecture\" + 0.007*\"deep_neural\" + 0.007*\"deep\" + 0.006*\"trained\" + 0.006*\"input\" + 0.006*\"image\" + 0.006*\"layer\" + 0.006*\"user\"'),\n",
       " (2,\n",
       "  '0.015*\"clustering\" + 0.011*\"space\" + 0.009*\"point\" + 0.008*\"cluster\" + 0.007*\"metric\" + 0.005*\"prior\" + 0.005*\"inference\" + 0.005*\"density\" + 0.005*\"mean\" + 0.005*\"measure\"'),\n",
       " (3,\n",
       "  '0.009*\"optimization\" + 0.009*\"gradient\" + 0.009*\"kernel\" + 0.007*\"setting\" + 0.007*\"bound\" + 0.007*\"solution\" + 0.006*\"stochastic\" + 0.006*\"linear\" + 0.006*\"rate\" + 0.005*\"approximation\"'),\n",
       " (4,\n",
       "  '0.007*\"dynamic\" + 0.007*\"node\" + 0.006*\"agent\" + 0.006*\"representation\" + 0.005*\"test\" + 0.005*\"process\" + 0.004*\"system\" + 0.004*\"variable\" + 0.004*\"complex\" + 0.004*\"time_series\"'),\n",
       " (5,\n",
       "  '0.012*\"image\" + 0.009*\"classifier\" + 0.008*\"domain\" + 0.008*\"label\" + 0.008*\"datasets\" + 0.007*\"representation\" + 0.006*\"convolutional_neural\" + 0.006*\"sparse\" + 0.006*\"signal\" + 0.006*\"multiple\"')]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_lda = LdaModel(corpus=filterd_bow, num_topics=6, id2word=dictionary, alpha= 'auto', eta=.01)\n",
    "filtered_lda.show_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My rationale for the `alpha` and `eta` parameters are as follows:**\n",
    "\n",
    "$\\alpha$ is a LDA parameter that relates to how evenly distributed topics are across documents. By default, the model assumes a document is approximately equally likely to have any topic. However, this is not the case here because all my documents relate to Machine Learning. So there are generic ML terms (and topics) that may be shared across more documents than others. Thus I set `alpha = 'asymmetric'`\n",
    "\n",
    "$\\eta$ in gensim is analogous to the parameter $\\beta$ in the formal LDA model. It signifies how many topics share a word. Low `eta` means that the model favors term exclusivity among topics. Again, because my corpus is so overlapping in nature, I want to set `eta` to be low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el51941403784002212485923554437\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el51941403784002212485923554437_data = {\"mdsDat\": {\"x\": [0.0858190946706517, -0.0673550068268773, 0.02242504790032095, 0.1300899361853229, -0.10122677842513117, -0.06975229350428715], \"y\": [0.04590634875621601, -0.057038554514410714, 0.06490603416317041, -0.05445772515501989, 0.06687604553273864, -0.06619214878269454], \"topics\": [1, 2, 3, 4, 5, 6], \"cluster\": [1, 1, 1, 1, 1, 1], \"Freq\": [16.38046646118164, 19.64348602294922, 13.535697937011719, 19.251148223876953, 18.633481979370117, 12.555709838867188]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\"], \"Freq\": [2029.0, 2019.0, 2815.0, 3116.0, 2037.0, 1584.0, 1454.0, 1136.0, 2688.0, 2817.0, 2392.0, 2684.0, 767.0, 1716.0, 3158.0, 2524.0, 2289.0, 2480.0, 1351.0, 1914.0, 1654.0, 1501.0, 1975.0, 2716.0, 1504.0, 2495.0, 1480.0, 3209.0, 1035.0, 1911.0, 271.1402282714844, 199.24195861816406, 206.07537841796875, 100.1870346069336, 104.42923736572266, 36.80613327026367, 186.8299102783203, 172.150146484375, 87.38520812988281, 165.26060485839844, 117.80380249023438, 1844.3663330078125, 90.81355285644531, 37.783451080322266, 45.3399772644043, 75.63134765625, 40.0439567565918, 95.62741088867188, 217.51585388183594, 304.3772888183594, 244.08795166015625, 63.081295013427734, 250.298095703125, 173.092041015625, 62.88190460205078, 64.16349029541016, 89.25045776367188, 97.4068603515625, 207.6952667236328, 117.80601501464844, 671.963623046875, 136.7906951904297, 260.97576904296875, 1759.437255859375, 1809.033447265625, 1478.630859375, 222.6006622314453, 883.67041015625, 1474.1202392578125, 212.3045654296875, 671.2752075195312, 984.2185668945312, 272.97662353515625, 546.1654663085938, 802.5147094726562, 876.0125122070312, 544.4232177734375, 918.6893920898438, 643.4359130859375, 385.59295654296875, 951.2544555664062, 532.9622192382812, 479.51531982421875, 673.7988891601562, 855.7412109375, 529.5596923828125, 665.7101440429688, 685.816162109375, 698.8887329101562, 515.787353515625, 661.2058715820312, 427.1600036621094, 634.6232299804688, 667.517578125, 651.6237182617188, 553.318603515625, 583.6965942382812, 524.5800170898438, 139.86915588378906, 135.75070190429688, 88.08366394042969, 144.3820037841797, 160.9621124267578, 292.9740905761719, 77.07756805419922, 170.29551696777344, 130.17440795898438, 98.26724243164062, 238.90098571777344, 68.62227630615234, 287.56890869140625, 140.70530700683594, 40.94615936279297, 1415.037841796875, 56.45546340942383, 92.68892669677734, 52.87008285522461, 60.04035568237305, 87.7584228515625, 111.66889953613281, 163.6661834716797, 1518.8984375, 468.3166198730469, 167.23471069335938, 62.73063659667969, 47.950843811035156, 153.6746368408203, 57.17529296875, 1849.3466796875, 118.50984954833984, 1118.721923828125, 2472.490966796875, 1367.8004150390625, 276.3316955566406, 932.6817626953125, 1185.662109375, 1054.091796875, 342.3678894042969, 208.3316650390625, 278.9241638183594, 275.0225524902344, 265.7449951171875, 477.4842834472656, 1010.378173828125, 1163.987060546875, 642.902099609375, 577.9376220703125, 363.15887451171875, 1163.3199462890625, 386.8796691894531, 494.893310546875, 339.08563232421875, 878.3949584960938, 577.2811889648438, 865.0529174804688, 786.1968994140625, 935.2945556640625, 589.5926513671875, 633.419189453125, 599.940185546875, 736.6387939453125, 669.6627807617188, 601.852294921875, 512.67236328125, 495.74566650390625, 584.1249389648438, 595.8062133789062, 626.5053100585938, 589.7050170898438, 565.1362915039062, 409.7380065917969, 391.263427734375, 171.0399932861328, 253.73536682128906, 121.16128540039062, 110.147216796875, 118.7691879272461, 185.0354766845703, 347.5458984375, 68.90074920654297, 122.7467041015625, 194.00286865234375, 194.16717529296875, 138.11346435546875, 210.76438903808594, 1946.92724609375, 70.83474731445312, 78.15193939208984, 72.99134063720703, 90.491455078125, 132.36685180664062, 1039.5201416015625, 242.33229064941406, 158.59278869628906, 62.930721282958984, 101.93839263916016, 518.2796020507812, 136.0135040283203, 582.0076904296875, 105.43570709228516, 641.9906005859375, 201.5297393798828, 163.34449768066406, 907.4249267578125, 378.4674987792969, 496.9614562988281, 333.124755859375, 588.324951171875, 1450.48486328125, 1157.9974365234375, 356.82977294921875, 243.06515502929688, 398.3802490234375, 715.8214111328125, 448.2427062988281, 591.8771362304688, 589.6139526367188, 669.4105834960938, 586.1076049804688, 501.1266784667969, 365.7651062011719, 474.5356750488281, 438.65594482421875, 502.43450927734375, 496.8651428222656, 439.43487548828125, 463.84429931640625, 421.8051452636719, 419.51568603515625, 416.7294616699219, 394.1744689941406, 197.8888702392578, 179.5867156982422, 125.91078186035156, 103.85094451904297, 150.81178283691406, 237.90887451171875, 156.59951782226562, 100.97492980957031, 188.0607452392578, 167.2379608154297, 630.0879516601562, 125.9825210571289, 49.361637115478516, 153.722900390625, 70.30812072753906, 94.09384155273438, 179.8263397216797, 59.662437438964844, 58.98160934448242, 536.77294921875, 224.8381805419922, 69.86653900146484, 325.36944580078125, 216.1741180419922, 52.29671096801758, 79.9004898071289, 130.23777770996094, 264.36297607421875, 88.90538024902344, 72.2813949584961, 160.84913635253906, 606.9100952148438, 702.6372680664062, 736.6359252929688, 202.03836059570312, 142.44964599609375, 237.6515350341797, 266.75543212890625, 452.18389892578125, 826.7512817382812, 475.1873779296875, 1744.510498046875, 494.7718505859375, 1685.5042724609375, 901.8324584960938, 1750.923828125, 548.1846923828125, 1173.366455078125, 1239.4571533203125, 638.1751708984375, 487.79302978515625, 715.2149658203125, 352.79913330078125, 898.558837890625, 1100.1629638671875, 518.3289794921875, 670.2939453125, 1217.33740234375, 452.80615234375, 1109.392578125, 1018.9376220703125, 1261.6805419921875, 754.1526489257812, 869.7080078125, 901.2907104492188, 970.1221313476562, 687.552490234375, 864.782470703125, 666.3276977539062, 651.6856079101562, 676.40234375, 655.5289916992188, 636.570068359375, 632.4560546875, 173.7298583984375, 185.88343811035156, 74.4583740234375, 53.78769302368164, 236.18568420410156, 112.27322387695312, 43.95895767211914, 100.58614349365234, 396.8025207519531, 148.99539184570312, 106.15062713623047, 59.71586227416992, 182.85159301757812, 160.78794860839844, 86.78782653808594, 134.93478393554688, 53.5549201965332, 87.14044952392578, 82.19872283935547, 131.3214569091797, 291.91583251953125, 161.57217407226562, 182.36732482910156, 35.915672302246094, 82.92023468017578, 145.69786071777344, 655.2174682617188, 428.49737548828125, 149.01806640625, 446.8908996582031, 321.8516845703125, 195.4826202392578, 343.7282409667969, 1169.6845703125, 571.6845092773438, 491.6050720214844, 152.45269775390625, 1323.9326171875, 671.1767578125, 685.254638671875, 1066.732421875, 563.7088012695312, 427.0098571777344, 394.1480712890625, 579.3591918945312, 363.3904724121094, 663.0241088867188, 360.9637145996094, 693.7536010742188, 603.5457763671875, 454.1731872558594, 376.56878662109375, 333.98779296875, 549.654541015625, 958.1704711914062, 765.8729248046875, 506.2235107421875, 513.1176147460938, 1024.5262451171875, 708.2835693359375, 925.336181640625, 576.063232421875, 709.1727294921875, 692.3320922851562, 583.9933471679688, 672.0960083007812, 584.8202514648438, 608.2798461914062, 553.0053100585938, 598.6640014648438, 591.2869262695312, 569.7644653320312, 554.695068359375, 214.52130126953125, 138.4831085205078, 206.83726501464844, 216.72398376464844, 67.54469299316406, 221.99044799804688, 48.40790557861328, 262.0703430175781, 119.52086639404297, 77.76020050048828, 101.90259552001953, 757.1400146484375, 68.2271728515625, 131.9120330810547, 153.37388610839844, 79.91799926757812, 68.99331665039062, 182.75270080566406, 105.84320068359375, 21.770381927490234, 78.80972290039062, 146.73504638671875, 279.3067932128906, 196.72048950195312, 76.29147338867188, 97.3156967163086, 149.021484375, 261.3876953125, 151.1772918701172, 105.44381713867188, 219.0060272216797, 396.8608093261719, 349.61810302734375, 316.3821105957031, 211.22120666503906, 181.8142852783203, 963.2649536132812, 1464.1058349609375, 310.74285888671875, 302.905517578125, 983.6444091796875, 726.5213012695312, 1056.8319091796875, 293.07568359375, 540.9508056640625, 571.2595825195312, 271.5466613769531, 755.5011596679688, 239.85549926757812, 266.97515869140625, 910.3369140625, 894.0887451171875, 669.2030639648438, 435.66632080078125, 656.7273559570312, 390.3908386230469, 393.671630859375, 551.5425415039062, 433.5788879394531, 386.3748779296875, 309.9801940917969, 299.9048767089844, 507.5960388183594, 481.3307800292969, 485.3933410644531, 417.5650939941406, 443.0225524902344, 395.7969970703125, 385.43170166015625, 376.95501708984375, 344.245361328125, 358.8299255371094, 357.4913024902344], \"Term\": [\"clustering\", \"estimator\", \"image\", \"neural_network\", \"deep_learning\", \"architecture\", \"deep_neural\", \"cluster\", \"error\", \"estimate\", \"gradient\", \"classifier\", \"convolutional_neural\", \"deep\", \"space\", \"kernel\", \"regression\", \"estimation\", \"layer\", \"bound\", \"label\", \"metric\", \"domain\", \"optimization\", \"node\", \"point\", \"user\", \"representation\", \"attack\", \"dynamic\", \"attention_mechanism\", \"company\", \"targeted\", \"collective\", \"bias_variance\", \"concentration_inequality\", \"thompson_sampling\", \"confidence_interval\", \"generalized_linear\", \"bootstrap\", \"subsampling\", \"estimator\", \"resampling\", \"oracle_inequality\", \"regression_coefficient\", \"degree_freedom\", \"information_criterion\", \"diagonal\", \"simulation_study\", \"linear_regression\", \"cross_validation\", \"mild_condition\", \"finite_sample\", \"unbiased\", \"weaker\", \"shrinkage\", \"parameter_tuning\", \"importance_sampling\", \"worker\", \"mean_squared\", \"variance\", \"variable_selection\", \"lasso\", \"error\", \"estimate\", \"regression\", \"covariates\", \"selection\", \"estimation\", \"aggregation\", \"risk\", \"bayesian\", \"asymptotic\", \"estimating\", \"procedure\", \"high_dimensional\", \"gaussian_process\", \"statistical\", \"ensemble\", \"estimated\", \"classifier\", \"probability\", \"empirical\", \"variable\", \"setting\", \"assumption\", \"optimal\", \"value\", \"example\", \"simulation\", \"test\", \"gaussian\", \"inference\", \"provide\", \"case\", \"design\", \"given\", \"known\", \"mini_batch\", \"safety\", \"social_medium\", \"drug\", \"customer\", \"platform\", \"digital\", \"skill\", \"backpropagation\", \"feed_forward\", \"hardware\", \"positive_negative\", \"convolutional\", \"shallow\", \"adoption\", \"deep_neural\", \"learnable\", \"team\", \"feedforward\", \"textual\", \"cross_entropy\", \"user_item\", \"fully_connected\", \"architecture\", \"recommendation\", \"recommender_system\", \"mri\", \"stored\", \"x\", \"suite\", \"deep_learning\", \"interface\", \"layer\", \"neural_network\", \"deep\", \"device\", \"train\", \"trained\", \"user\", \"generator\", \"propagation\", \"net\", \"adversary\", \"neuron\", \"memory\", \"policy\", \"input\", \"environment\", \"attack\", \"exploration\", \"image\", \"text\", \"adversarial\", \"item\", \"state_art\", \"reinforcement_learning\", \"inference\", \"learn\", \"accuracy\", \"high\", \"design\", \"system\", \"representation\", \"existing\", \"experiment\", \"loss\", \"output\", \"efficient\", \"large\", \"datasets\", \"demonstrate\", \"present\", \"recurrent\", \"activation_function\", \"text_classification\", \"cifar\", \"interpreting\", \"release\", \"directional\", \"wasserstein_distance\", \"quantization\", \"give_rise\", \"number_cluster\", \"perception\", \"optimal_transport\", \"fine_grained\", \"spectral_clustering\", \"clustering\", \"subspace_clustering\", \"hierarchical_clustering\", \"mean_clustering\", \"origin\", \"density_estimation\", \"cluster\", \"pruning\", \"kullback_leibler\", \"satisfied\", \"proximity\", \"student\", \"trial\", \"divergence\", \"symmetry\", \"density\", \"partition\", \"cloud\", \"metric\", \"flow\", \"mixture\", \"latent_space\", \"distance\", \"space\", \"point\", \"subspace\", \"pca\", \"generative_model\", \"prior\", \"map\", \"mean\", \"measure\", \"inference\", \"approximation\", \"sequence\", \"family\", \"weight\", \"allows\", \"input\", \"datasets\", \"property\", \"given\", \"state\", \"large\", \"process\", \"representation\", \"shot\", \"batch_size\", \"actor_critic\", \"gradually\", \"drive\", \"admm\", \"differentially_private\", \"saddle_point\", \"differential_privacy\", \"strongly_convex\", \"sgd\", \"non_smooth\", \"strong_convexity\", \"ucb\", \"nonsmooth\", \"nonconvex_optimization\", \"linear_convergence\", \"best_known\", \"iteration_complexity\", \"regret\", \"descent_sgd\", \"alternating_minimization\", \"arm\", \"regret_bound\", \"upper_lower\", \"primal\", \"lipschitz\", \"step_size\", \"primal_dual\", \"exact_recovery\", \"proximal\", \"non_convex\", \"convex\", \"gradient_descent\", \"nmf\", \"stationary_point\", \"stochastic_optimization\", \"nonconvex\", \"descent\", \"stochastic_gradient\", \"convergence_rate\", \"gradient\", \"lower_bound\", \"kernel\", \"convergence\", \"optimization\", \"norm\", \"stochastic\", \"bound\", \"loss_function\", \"optimization_problem\", \"guarantee\", \"minimization\", \"prove\", \"rate\", \"iteration\", \"reward\", \"solution\", \"objective_function\", \"linear\", \"approximation\", \"setting\", \"online\", \"noise\", \"optimal\", \"provide\", \"objective\", \"case\", \"constraint\", \"loss\", \"general\", \"order\", \"term\", \"particular\", \"health\", \"intervention\", \"electronic_health\", \"inform\", \"vehicle\", \"compound\", \"cohort\", \"diagnostic\", \"robot\", \"link_prediction\", \"imputation\", \"community_structure\", \"age\", \"healthcare\", \"personalized\", \"driving\", \"dag\", \"duration\", \"short_term\", \"stock\", \"entity\", \"relational\", \"forecast\", \"directed_acyclic\", \"gradient_boosting\", \"opportunity\", \"patient\", \"forecasting\", \"cognitive\", \"causal\", \"clinical\", \"social\", \"disease\", \"node\", \"event\", \"topic\", \"trend\", \"dynamic\", \"interaction\", \"object\", \"agent\", \"predict\", \"community\", \"attribute\", \"tree\", \"interpretable\", \"pattern\", \"predicting\", \"time_series\", \"individual\", \"embeddings\", \"ranking\", \"edge\", \"score\", \"test\", \"system\", \"change\", \"decision\", \"representation\", \"complex\", \"process\", \"human\", \"variable\", \"state\", \"behavior\", \"dataset\", \"type\", \"learn\", \"real_world\", \"present\", \"datasets\", \"case\", \"multiple\", \"attacker\", \"multi_layer\", \"target_domain\", \"source_domain\", \"feedforward_neural\", \"long_short\", \"hypothesis_test\", \"domain_adaptation\", \"source_target\", \"pooling\", \"visually\", \"convolutional_neural\", \"varied\", \"multi_view\", \"eeg\", \"ica\", \"descriptor\", \"anomaly\", \"outlier_detection\", \"structured_sparsity\", \"machine_svm\", \"safe\", \"traffic\", \"modality\", \"analytics\", \"embedding_space\", \"multi_label\", \"multi_task\", \"scene\", \"imbalanced\", \"anomaly_detection\", \"sensor\", \"channel\", \"video\", \"multimodal\", \"svm\", \"label\", \"image\", \"support_vector\", \"outlier\", \"domain\", \"signal\", \"classifier\", \"segmentation\", \"group\", \"multi\", \"transfer\", \"sparse\", \"convolution\", \"labeled\", \"datasets\", \"representation\", \"multiple\", \"attack\", \"state_art\", \"source\", \"detection\", \"dataset\", \"instance\", \"component\", \"spatial\", \"sparsity\", \"space\", \"existing\", \"accuracy\", \"vector\", \"novel\", \"level\", \"target\", \"paper_propose\", \"regularization\", \"demonstrate\", \"present\"], \"Total\": [2029.0, 2019.0, 2815.0, 3116.0, 2037.0, 1584.0, 1454.0, 1136.0, 2688.0, 2817.0, 2392.0, 2684.0, 767.0, 1716.0, 3158.0, 2524.0, 2289.0, 2480.0, 1351.0, 1914.0, 1654.0, 1501.0, 1975.0, 2716.0, 1504.0, 2495.0, 1480.0, 3209.0, 1035.0, 1911.0, 271.1894836425781, 199.29119873046875, 206.13006591796875, 100.25525665283203, 105.68302917480469, 37.90103530883789, 193.43716430664062, 178.76226806640625, 93.33826446533203, 177.33297729492188, 128.0991668701172, 2019.965576171875, 100.57960510253906, 42.17267608642578, 50.7358512878418, 85.9109878540039, 46.092533111572266, 110.68020629882812, 253.94020080566406, 359.6106262207031, 290.1636047363281, 75.47830963134766, 306.4831848144531, 212.2120361328125, 77.67330169677734, 80.02468872070312, 112.03963470458984, 122.65840911865234, 261.7100830078125, 148.9462432861328, 882.5656127929688, 174.29156494140625, 348.47174072265625, 2688.741943359375, 2817.889892578125, 2289.6240234375, 298.2989501953125, 1357.9605712890625, 2480.5673828125, 286.0378723144531, 1077.7969970703125, 1694.8072509765625, 387.08270263671875, 895.2816772460938, 1533.80419921875, 1716.7640380859375, 966.0966186523438, 1930.65673828125, 1206.231689453125, 652.4406127929688, 2684.83154296875, 1141.87451171875, 983.64013671875, 1830.9366455078125, 3076.116943359375, 1298.365234375, 2011.152587890625, 2206.3310546875, 2335.070068359375, 1301.983154296875, 2382.57470703125, 963.6455078125, 2462.495849609375, 3047.67138671875, 2885.066162109375, 1887.2520751953125, 2631.869140625, 2103.314453125, 139.92654418945312, 135.8123321533203, 88.22100830078125, 144.80029296875, 161.47317504882812, 294.4916687011719, 77.50220489501953, 172.182373046875, 131.74276733398438, 99.56476593017578, 242.13523864746094, 69.64336395263672, 292.4714660644531, 143.6619873046875, 42.05357360839844, 1454.4267578125, 58.07344055175781, 95.48343658447266, 54.668033599853516, 62.08638381958008, 90.93013000488281, 115.9546127319336, 170.53366088867188, 1584.1617431640625, 489.9402160644531, 175.35415649414062, 65.99683380126953, 51.08832931518555, 164.78013610839844, 61.348995208740234, 2037.495361328125, 128.11624145507812, 1351.179443359375, 3116.755615234375, 1716.086669921875, 314.51800537109375, 1160.649169921875, 1663.159423828125, 1480.995849609375, 424.5986328125, 243.6857147216797, 361.652099609375, 365.0491027832031, 354.03155517578125, 751.1156616210938, 2000.4688720703125, 2600.69140625, 1172.8050537109375, 1035.25537109375, 538.6888427734375, 2815.71044921875, 608.25390625, 908.3050537109375, 521.4942016601562, 2457.634521484375, 1254.50390625, 2462.495849609375, 2173.6083984375, 2989.9501953125, 1483.069580078125, 1887.2520751953125, 1709.5986328125, 3209.46337890625, 2695.1884765625, 2222.538330078125, 1432.5447998046875, 1317.2833251953125, 2201.234375, 2487.528076171875, 3007.024169921875, 2674.572265625, 2763.137451171875, 409.7900085449219, 391.3456115722656, 171.09217834472656, 253.81982421875, 121.21330261230469, 110.19923400878906, 118.8337173461914, 185.41607666015625, 348.4646301269531, 69.10291290283203, 123.65765380859375, 197.15269470214844, 199.46681213378906, 142.86122131347656, 219.54266357421875, 2029.6427001953125, 74.67086791992188, 82.50543212890625, 77.79146575927734, 96.88717651367188, 143.6148223876953, 1136.5347900390625, 266.0115051269531, 178.17794799804688, 71.56553649902344, 116.14884948730469, 606.4035034179688, 159.85646057128906, 686.54248046875, 124.97235107421875, 846.176513671875, 248.054443359375, 199.18203735351562, 1501.6563720703125, 538.779541015625, 763.2623291015625, 485.17041015625, 998.951171875, 3158.7265625, 2495.44482421875, 555.6671142578125, 336.5162658691406, 706.5056762695312, 1834.5947265625, 915.5095825195312, 1488.123779296875, 1692.5048828125, 2462.495849609375, 2155.27197265625, 1565.592041015625, 830.4996337890625, 1700.3397216796875, 1677.8533935546875, 2600.69140625, 3007.024169921875, 1988.1910400390625, 2631.869140625, 1816.7828369140625, 2487.528076171875, 2763.8759765625, 3209.46337890625, 197.94125366210938, 179.65850830078125, 125.9649429321289, 103.90335845947266, 150.91281127929688, 238.15371704101562, 156.7886505126953, 101.16299438476562, 189.54019165039062, 168.95071411132812, 640.7705078125, 128.2927703857422, 50.298126220703125, 156.93251037597656, 71.87030792236328, 96.60755157470703, 185.01779174804688, 61.85658264160156, 61.3617057800293, 560.4724731445312, 235.1533966064453, 73.12855529785156, 341.50341796875, 227.55120849609375, 55.14125061035156, 84.26964569091797, 137.41357421875, 279.0301818847656, 94.1115951538086, 76.84169006347656, 172.0992431640625, 662.170654296875, 773.8717651367188, 820.9727783203125, 217.60789489746094, 152.2710418701172, 258.4881591796875, 296.1811828613281, 522.0686645507812, 1002.928955078125, 565.6726684570312, 2392.03955078125, 610.1368408203125, 2524.090576171875, 1230.0621337890625, 2716.3486328125, 706.718994140625, 1758.4608154296875, 1914.75927734375, 909.2334594726562, 650.451416015625, 1083.36328125, 437.92327880859375, 1454.6927490234375, 1932.7591552734375, 724.9036865234375, 1056.801513671875, 2446.936767578125, 624.087646484375, 2266.234375, 2155.27197265625, 3076.116943359375, 1428.14697265625, 1801.2666015625, 2011.152587890625, 3047.67138671875, 1428.19921875, 2885.066162109375, 1482.83349609375, 1432.5447998046875, 1861.1307373046875, 2209.1044921875, 2011.5472412109375, 1936.0697021484375, 173.8701629638672, 187.09591674804688, 75.23734283447266, 54.39594268798828, 240.24754333496094, 114.23143005371094, 45.07802963256836, 103.43193054199219, 408.65093994140625, 153.7434539794922, 110.00091552734375, 61.916194915771484, 189.68797302246094, 167.80470275878906, 90.7210922241211, 142.27523803710938, 56.8112678527832, 92.44309997558594, 87.81330871582031, 140.51568603515625, 312.6191711425781, 173.0675811767578, 195.7521209716797, 38.90501022338867, 90.24577331542969, 158.9945831298828, 716.4810791015625, 468.779296875, 164.65908813476562, 495.5654296875, 360.96746826171875, 217.64627075195312, 405.9649658203125, 1504.809814453125, 706.05859375, 609.55859375, 171.40086364746094, 1911.952392578125, 944.5874633789062, 980.4384155273438, 1652.6715087890625, 791.1240844726562, 568.920654296875, 522.55517578125, 842.5145874023438, 479.7041015625, 1067.716796875, 495.011962890625, 1166.989990234375, 1037.958740234375, 705.5673828125, 546.1961059570312, 471.5322570800781, 1001.3751220703125, 2382.57470703125, 1709.5986328125, 900.1593017578125, 929.4904174804688, 3209.46337890625, 1676.2628173828125, 2763.8759765625, 1166.45166015625, 1830.9366455078125, 1816.7828369140625, 1352.4327392578125, 2236.81298828125, 1619.8282470703125, 2173.6083984375, 1648.74169921875, 2763.137451171875, 3007.024169921875, 2885.066162109375, 2142.15771484375, 214.59231567382812, 138.5382843017578, 206.94696044921875, 216.90289306640625, 67.62278747558594, 222.27716064453125, 48.50339126586914, 262.7298278808594, 119.92488098144531, 78.48955535888672, 103.23285675048828, 767.7329711914062, 69.8743667602539, 135.1667022705078, 161.81150817871094, 84.55875396728516, 73.2625503540039, 194.28359985351562, 115.74790954589844, 23.932113647460938, 87.14035034179688, 162.52415466308594, 316.7082214355469, 223.1587371826172, 86.96845245361328, 111.69984436035156, 172.08128356933594, 303.3760986328125, 179.44189453125, 125.21675109863281, 261.9967956542969, 506.669921875, 450.02911376953125, 413.97076416015625, 269.75750732421875, 227.6724090576172, 1654.2578125, 2815.71044921875, 435.04791259765625, 441.51910400390625, 1975.383544921875, 1459.43212890625, 2684.83154296875, 450.1652526855469, 1094.1251220703125, 1191.084716796875, 411.8124694824219, 1964.6748046875, 343.8306579589844, 406.94622802734375, 3007.024169921875, 3209.46337890625, 2142.15771484375, 1035.25537109375, 2457.634521484375, 914.6995849609375, 991.825439453125, 2236.81298828125, 1279.0816650390625, 1136.6533203125, 617.5552978515625, 563.4935302734375, 3158.7265625, 2695.1884765625, 2989.9501953125, 1759.53857421875, 2388.2236328125, 1490.6141357421875, 1594.475341796875, 1445.167236328125, 1171.7054443359375, 2674.572265625, 2763.137451171875], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.808899998664856, 1.8087999820709229, 1.8087999820709229, 1.80840003490448, 1.7970999479293823, 1.7798000574111938, 1.7742999792099, 1.771399974822998, 1.7431999444961548, 1.7386000156402588, 1.7252999544143677, 1.7180999517440796, 1.7069000005722046, 1.6992000341415405, 1.6965999603271484, 1.6815999746322632, 1.6684000492095947, 1.6628999710083008, 1.6542999744415283, 1.642300009727478, 1.636199951171875, 1.629699945449829, 1.606600046157837, 1.605299949645996, 1.5978000164031982, 1.5881999731063843, 1.5816999673843384, 1.5786000490188599, 1.5779000520706177, 1.5744999647140503, 1.5364999771118164, 1.5667999982833862, 1.5199999809265137, 1.3849999904632568, 1.3659000396728516, 1.3717999458312988, 1.5163999795913696, 1.3794000148773193, 1.288699984550476, 1.5110000371932983, 1.3356000185012817, 1.2655999660491943, 1.4598000049591064, 1.3149000406265259, 1.1612999439239502, 1.136299967765808, 1.2354999780654907, 1.0664000511169434, 1.1806000471115112, 1.2831000089645386, 0.7714999914169312, 1.0470999479293823, 1.0906000137329102, 0.8094000220298767, 0.5296000242233276, 0.9122999906539917, 0.703499972820282, 0.6406000256538391, 0.6028000116348267, 0.8830999732017517, 0.5271999835968018, 0.9955000281333923, 0.45320001244544983, 0.2904999852180481, 0.32120001316070557, 0.582099974155426, 0.30300000309944153, 0.4203999936580658, 1.6269999742507935, 1.6269999742507935, 1.6259000301361084, 1.624500036239624, 1.6243000030517578, 1.6223000288009644, 1.621899962425232, 1.6164000034332275, 1.615399956703186, 1.614300012588501, 1.6139999628067017, 1.6126999855041504, 1.6104999780654907, 1.606600046157837, 1.6007000207901, 1.600000023841858, 1.5992000102996826, 1.5976999998092651, 1.593999981880188, 1.5938999652862549, 1.5918999910354614, 1.5898000001907349, 1.586300015449524, 1.5853999853134155, 1.5822999477386475, 1.5800000429153442, 1.57669997215271, 1.5640000104904175, 1.5576000213623047, 1.5570000410079956, 1.530500054359436, 1.5494999885559082, 1.438599944114685, 1.395900011062622, 1.4005999565124512, 1.4980000257492065, 1.4088000059127808, 1.2890000343322754, 1.2874000072479248, 1.4121999740600586, 1.4707000255584717, 1.3676999807357788, 1.3442000150680542, 1.3406000137329102, 1.174399971961975, 0.9444000124931335, 0.8234999775886536, 1.0262999534606934, 1.0444999933242798, 1.2331000566482544, 0.7434999942779541, 1.1749000549316406, 1.0202000141143799, 1.1970000267028809, 0.5985999703407288, 0.8513000011444092, 0.5813000202178955, 0.6104999780654907, 0.4652999937534332, 0.7049999833106995, 0.5357000231742859, 0.5802000164985657, 0.15569999814033508, 0.23499999940395355, 0.32100000977516174, 0.5999000072479248, 0.6502000093460083, 0.30079999566078186, 0.19830000400543213, 0.05889999866485596, 0.11550000309944153, 0.04039999842643738, 1.9996999502182007, 1.9996000528335571, 1.999500036239624, 1.999500036239624, 1.999400019645691, 1.999400019645691, 1.9993000030517578, 1.9977999925613403, 1.9972000122070312, 1.996899962425232, 1.992400050163269, 1.9837000370025635, 1.9729000329971313, 1.965999960899353, 1.9589999914169312, 1.9581999778747559, 1.947100043296814, 1.9456000328063965, 1.9361000061035156, 1.93149995803833, 1.9183000326156616, 1.910599946975708, 1.906599998474121, 1.8833999633789062, 1.8712999820709229, 1.8693000078201294, 1.8428000211715698, 1.8382999897003174, 1.8346999883651733, 1.829800009727478, 1.7237000465393066, 1.792099952697754, 1.8014999628067017, 1.4960999488830566, 1.6467000246047974, 1.5707999467849731, 1.623900055885315, 1.4703999757766724, 1.22160005569458, 1.232100009918213, 1.5569000244140625, 1.6744999885559082, 1.426900029182434, 1.0586999654769897, 1.2856999635696411, 1.0779000520706177, 0.9452999830245972, 0.6973000168800354, 0.697700023651123, 0.8607000112533569, 1.179800033569336, 0.7235999703407288, 0.65829998254776, 0.35580000281333923, 0.19949999451637268, 0.4902999997138977, 0.2639000117778778, 0.5396000146865845, 0.2198999971151352, 0.10790000110864639, -0.09719999879598618, 1.6473000049591064, 1.6471999883651733, 1.6471999883651733, 1.6470999717712402, 1.6469000577926636, 1.6466000080108643, 1.646399974822998, 1.6456999778747559, 1.639799952507019, 1.6374000310897827, 1.6308000087738037, 1.6294000148773193, 1.6288000345230103, 1.6268999576568604, 1.625599980354309, 1.6211999654769897, 1.6190999746322632, 1.6115000247955322, 1.6080000400543213, 1.6044000387191772, 1.6026999950408936, 1.6019999980926514, 1.5992000102996826, 1.5963000059127808, 1.594599962234497, 1.5944000482559204, 1.593999981880188, 1.5936000347137451, 1.5907000303268433, 1.586400032043457, 1.5800000429153442, 1.5605000257492065, 1.5509999990463257, 1.539199948310852, 1.5734000205993652, 1.580899953842163, 1.563599944114685, 1.5429999828338623, 1.5039000511169434, 1.4543999433517456, 1.4732999801635742, 1.3319000005722046, 1.437999963760376, 1.2438000440597534, 1.3372000455856323, 1.2085000276565552, 1.3935999870300293, 1.2430000305175781, 1.2127000093460083, 1.2935999631881714, 1.3597999811172485, 1.2323999404907227, 1.43149995803833, 1.1657999753952026, 1.0841000080108643, 1.3121999502182007, 1.1922999620437622, 0.949400007724762, 1.326799988746643, 0.9333000183105469, 0.8984000086784363, 0.7563999891281128, 1.0090999603271484, 0.9194999933242798, 0.8450000286102295, 0.5029000043869019, 0.9165999889373779, 0.44279998540878296, 0.8476999998092651, 0.8600000143051147, 0.6353999972343445, 0.4327000081539154, 0.4970000088214874, 0.5288000106811523, 1.6793999671936035, 1.673699975013733, 1.669800043106079, 1.6690000295639038, 1.6632000207901, 1.6628999710083008, 1.6550999879837036, 1.6523000001907349, 1.6507999897003174, 1.648800015449524, 1.6446000337600708, 1.6440000534057617, 1.6434999704360962, 1.6375000476837158, 1.6359000205993652, 1.6272000074386597, 1.6211999654769897, 1.6210999488830566, 1.6140999794006348, 1.6124999523162842, 1.6117000579833984, 1.6115000247955322, 1.6094000339508057, 1.6002999544143677, 1.5956000089645386, 1.592900037765503, 1.5908000469207764, 1.590399980545044, 1.580399990081787, 1.576799988746643, 1.565500020980835, 1.5728000402450562, 1.513800024986267, 1.4283000230789185, 1.469099998474121, 1.4651999473571777, 1.563099980354309, 1.3127000331878662, 1.3385000228881836, 1.3220000267028809, 1.242400050163269, 1.3413000106811523, 1.3933000564575195, 1.3982000350952148, 1.3056999444961548, 1.402500033378601, 1.2036999464035034, 1.364400029182434, 1.160099983215332, 1.1380000114440918, 1.2396999597549438, 1.3083000183105469, 1.3352999687194824, 1.080399990081787, 0.7692999839782715, 0.8772000074386597, 1.104599952697754, 1.0860999822616577, 0.5382999777793884, 0.8187000155448914, 0.5860000252723694, 0.9746999740600586, 0.7317000031471252, 0.715499997138977, 0.840399980545044, 0.47780001163482666, 0.6614000201225281, 0.4066999852657318, 0.5878000259399414, 0.15080000460147858, 0.05380000174045563, 0.05810000002384186, 0.32910001277923584, 2.074700117111206, 2.0745999813079834, 2.07450008392334, 2.074199914932251, 2.0738000869750977, 2.073699951171875, 2.072999954223633, 2.072499990463257, 2.0715999603271484, 2.065700054168701, 2.062000036239624, 2.0611000061035156, 2.051100015640259, 2.050600051879883, 2.021399974822998, 2.0185000896453857, 2.015000104904175, 2.0137999057769775, 1.9854999780654907, 1.980299949645996, 1.9744999408721924, 1.9728000164031982, 1.9493000507354736, 1.9488999843597412, 1.944000005722046, 1.9371000528335571, 1.9311000108718872, 1.9259999990463257, 1.9035999774932861, 1.9031000137329102, 1.895799994468689, 1.8307000398635864, 1.8224999904632568, 1.8061000108718872, 1.830399990081787, 1.850100040435791, 1.5341999530792236, 1.4210000038146973, 1.7384999990463257, 1.698199987411499, 1.3776999711990356, 1.377500057220459, 1.142699956893921, 1.645799994468689, 1.3705999851226807, 1.3401999473571777, 1.6585999727249146, 1.1193000078201294, 1.714900016784668, 1.653499960899353, 0.8801000118255615, 0.7968999743461609, 0.9114999771118164, 1.2094999551773071, 0.755299985408783, 1.2235000133514404, 1.1510000228881836, 0.6748999953269958, 0.9932000041007996, 0.9959999918937683, 1.385699987411499, 1.4443000555038452, 0.2468000054359436, 0.3522999882698059, 0.25690001249313354, 0.6366000175476074, 0.3903000056743622, 0.7490000128746033, 0.6550999879837036, 0.7311000227928162, 0.8500999808311462, 0.06629999727010727, 0.029999999329447746], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -6.3684000968933105, -6.676499843597412, -6.6427998542785645, -7.363999843597412, -7.322500228881836, -8.365400314331055, -6.740799903869629, -6.822700023651123, -7.500699996948242, -6.863500118255615, -7.202000141143799, -4.451099872589111, -7.462200164794922, -8.339099884033203, -8.156800270080566, -7.645100116729736, -8.281000137329102, -7.410600185394287, -6.588699817657471, -6.252799987792969, -6.473499774932861, -7.826600074768066, -6.448400020599365, -6.817200183868408, -7.829800128936768, -7.809599876403809, -7.479599952697754, -7.392099857330322, -6.634900093078613, -7.202000141143799, -5.4608001708984375, -7.052599906921387, -6.406599998474121, -4.498300075531006, -4.4704999923706055, -4.672100067138672, -6.5655999183654785, -5.1869001388549805, -4.67519998550415, -6.61299991607666, -5.4618000984191895, -5.07919979095459, -6.361599922180176, -5.668099880218506, -5.283299922943115, -5.1956000328063965, -5.671299934387207, -5.148099899291992, -5.504199981689453, -6.016200065612793, -5.1132001876831055, -5.692599773406982, -5.7982001304626465, -5.458099842071533, -5.218999862670898, -5.698999881744385, -5.470200061798096, -5.440400123596191, -5.421500205993652, -5.725299835205078, -5.4770002365112305, -5.913899898529053, -5.51800012588501, -5.46750020980835, -5.491600036621094, -5.655099868774414, -5.601600170135498, -5.708399772644043, -7.211999893188477, -7.2418999671936035, -7.6743998527526855, -7.180200099945068, -7.071499824523926, -6.472599983215332, -7.8078999519348145, -7.015100002288818, -7.28380012512207, -7.565000057220459, -6.676599979400635, -7.924099922180176, -6.491199970245361, -7.205999851226807, -8.440400123596191, -4.897799968719482, -8.119199752807617, -7.6234002113342285, -8.184800148010254, -8.057700157165527, -7.678100109100342, -7.437099933624268, -7.054800033569336, -4.826900005340576, -6.003499984741211, -7.033299922943115, -8.013799667358398, -8.282500267028809, -7.117800235748291, -8.106599807739258, -4.630099773406982, -7.377699851989746, -5.132699966430664, -4.339700222015381, -4.931700229644775, -6.531099796295166, -5.314599990844727, -5.0746002197265625, -5.192200183868408, -6.316800117492676, -6.813499927520752, -6.521699905395508, -6.535799980163574, -6.570099830627441, -5.984099864959717, -5.234600067138672, -5.093100070953369, -5.686699867248535, -5.7932000160217285, -6.257800102233887, -5.093599796295166, -6.1946001052856445, -5.948299884796143, -6.326399803161621, -5.374599933624268, -5.794300079345703, -5.389900207519531, -5.485499858856201, -5.311800003051758, -5.773200035095215, -5.701499938964844, -5.755799770355225, -5.550600051879883, -5.645899772644043, -5.752699851989746, -5.913000106811523, -5.946599960327148, -5.782599925994873, -5.762800216674805, -5.712500095367432, -5.773099899291992, -5.8155999183654785, -5.764699935913086, -5.8109002113342285, -6.638400077819824, -6.24399995803833, -6.983099937438965, -7.078400135040283, -7.0030999183654785, -6.559700012207031, -5.9293999671936035, -7.547599792480469, -6.970099925994873, -6.512400150299072, -6.511499881744385, -6.852200031280518, -6.429500102996826, -4.206299781799316, -7.519899845123291, -7.421599864959717, -7.4899001121521, -7.275000095367432, -6.894700050354004, -4.833700180053711, -6.289899826049805, -6.713900089263916, -7.638199806213379, -7.155900001525879, -5.529699802398682, -6.867499828338623, -5.41379976272583, -7.122200012207031, -5.315700054168701, -6.474299907684326, -6.6844000816345215, -4.969600200653076, -5.844099998474121, -5.571700096130371, -5.971700191497803, -5.4029998779296875, -4.5005998611450195, -4.725800037384033, -5.9029998779296875, -6.286900043487549, -5.792900085449219, -5.2067999839782715, -5.674900054931641, -5.396999835968018, -5.4008002281188965, -5.273900032043457, -5.406799793243408, -5.563399791717529, -5.878300189971924, -5.6178998947143555, -5.696499824523926, -5.560800075531006, -5.571899890899658, -5.694799900054932, -5.640699863433838, -5.7357001304626465, -5.741199970245361, -5.747799873352051, -5.803500175476074, -6.844799995422363, -6.941800117492676, -7.296899795532227, -7.489500045776367, -7.116499900817871, -6.660600185394287, -7.078800201416016, -7.517600059509277, -6.895699977874756, -7.0131001472473145, -5.686600208282471, -7.29640007019043, -8.23330020904541, -7.097300052642822, -7.8796000480651855, -7.588200092315674, -6.940499782562256, -8.043800354003906, -8.055299758911133, -5.84689998626709, -6.717100143432617, -7.885900020599365, -6.347499847412109, -6.756400108337402, -8.175600051879883, -7.751699924468994, -7.2631001472473145, -6.555200099945068, -7.644899845123291, -7.851900100708008, -7.052000045776367, -5.724100112915039, -5.577700138092041, -5.530399799346924, -6.823999881744385, -7.173500061035156, -6.6616997718811035, -6.546199798583984, -6.018400192260742, -5.414999961853027, -5.968800067901611, -4.668300151824951, -5.928400039672852, -4.702700138092041, -5.328100204467773, -4.664599895477295, -5.825900077819824, -5.064899921417236, -5.0100998878479, -5.673900127410889, -5.942599773406982, -5.559899806976318, -6.266600131988525, -5.331699848175049, -5.129300117492676, -5.881899833679199, -5.624800205230713, -5.02810001373291, -6.017000198364258, -5.1209001541137695, -5.205999851226807, -4.992300033569336, -5.506899833679199, -5.364299774169922, -5.328700065612793, -5.255099773406982, -5.599400043487549, -5.369999885559082, -5.63070011138916, -5.652900218963623, -5.615699768066406, -5.64709997177124, -5.676400184631348, -5.6828999519348145, -6.942399978637695, -6.874800205230713, -7.789599895477295, -8.114800453186035, -6.635300159454346, -7.379000186920166, -8.31659984588623, -7.488900184631348, -6.116399765014648, -7.0960001945495605, -7.434999942779541, -8.010299682617188, -6.891200065612793, -7.019800186157227, -7.63640022277832, -7.195099830627441, -8.119199752807617, -7.632400035858154, -7.690700054168701, -7.2221999168396, -6.423399925231934, -7.014900207519531, -6.893899917602539, -8.518699645996094, -7.682000160217285, -7.1184000968933105, -5.6149001121521, -6.039599895477295, -7.095799922943115, -5.997600078582764, -6.325799942016602, -6.824399948120117, -6.260000228881836, -5.035399913787842, -5.751299858093262, -5.902200222015381, -7.072999954223633, -4.911499977111816, -5.59089994430542, -5.570099830627441, -5.127500057220459, -5.765399932861328, -6.043099880218506, -6.123199939727783, -5.73799991607666, -6.204400062561035, -5.603099822998047, -6.211100101470947, -5.557799816131592, -5.6971001625061035, -5.981400012969971, -6.168799877166748, -6.28879976272583, -5.790599822998047, -5.234899997711182, -5.458899974822998, -5.872900009155273, -5.859399795532227, -5.167900085449219, -5.5370001792907715, -5.269700050354004, -5.74370002746582, -5.535799980163574, -5.559800148010254, -5.730000019073486, -5.5894999504089355, -5.728600025177002, -5.689300060272217, -5.7845001220703125, -5.7052001953125, -5.717599868774414, -5.754700183868408, -5.781499862670898, -6.336699962615967, -6.774400234222412, -6.373199939727783, -6.326499938964844, -7.492300033569336, -6.302499771118164, -7.825399875640869, -6.136499881744385, -6.921599864959717, -7.351500034332275, -7.081099987030029, -5.0756001472473145, -7.4822998046875, -6.822999954223633, -6.6722002029418945, -7.324100017547607, -7.471099853515625, -6.497000217437744, -7.043099880218506, -8.624600410461426, -7.338099956512451, -6.7164998054504395, -6.072800159454346, -6.423299789428711, -7.370500087738037, -7.127099990844727, -6.701000213623047, -6.139100074768066, -6.686699867248535, -7.046899795532227, -6.315999984741211, -5.721499919891357, -5.848299980163574, -5.948200225830078, -6.352200031280518, -6.502099990844727, -4.834799766540527, -4.416100025177002, -5.966100215911865, -5.991700172424316, -4.813799858093262, -5.116799831390381, -4.742099761962891, -6.024700164794922, -5.411799907684326, -5.3572998046875, -6.10099983215332, -5.077700138092041, -6.225100040435791, -6.1178998947143555, -4.891300201416016, -4.909299850463867, -5.198999881744385, -5.628200054168701, -5.217800140380859, -5.73799991607666, -5.729599952697754, -5.392399787902832, -5.632999897003174, -5.748300075531006, -5.968599796295166, -6.0015997886657715, -5.475399971008301, -5.528500080108643, -5.520100116729736, -5.6707000732421875, -5.611499786376953, -5.7241997718811035, -5.750699996948242, -5.7729997634887695, -5.863699913024902, -5.822299957275391, -5.826000213623047]}, \"token.table\": {\"Topic\": [1, 2, 3, 4, 5, 6, 3, 4, 4, 2, 6, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 1, 2, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 4, 2, 3, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 6, 1, 1, 2, 3, 4, 5, 6, 2, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 6, 1, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 1, 2, 3, 4, 5, 6, 2, 3, 5, 6, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 5, 6, 3, 5, 1, 1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 4, 5, 1, 4, 1, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 5, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 5, 1, 2, 3, 4, 5, 6, 2, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 5, 6, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 4, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 6, 1, 2, 3, 5, 2, 4, 4, 2, 3, 5, 6, 3, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 6, 4, 2, 3, 4, 5, 2, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 6, 1, 2, 3, 4, 5, 6, 3, 5, 2, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 2, 4, 6, 1, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 2, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 5, 1, 2, 3, 4, 6, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 6, 5, 3, 5, 6, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 1, 2, 3, 4, 1, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 5, 1, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 1, 2, 3, 4, 5, 6, 3, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 4, 6, 1, 2, 3, 4, 5, 6, 2, 5, 1, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 2, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 2, 5, 6, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 4, 6, 6, 1, 2, 3, 4, 5, 6, 2, 4, 5, 6, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 4, 6, 1, 3, 4, 5, 6, 1, 4, 1, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 5, 6, 1, 2, 3, 4, 5, 6, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 3, 4, 5, 6, 3, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 1, 5, 6, 2, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 6, 2, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 4, 5, 6, 2, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 6, 3, 6, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 3, 1, 2, 3, 4, 5, 6, 1, 3, 4, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 5, 6, 3, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 5, 6, 4, 1, 6, 2, 2, 3, 5, 2, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 4, 2, 4, 2, 3, 5, 4, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 1, 2, 3, 4, 5, 6, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 5, 6, 1, 2, 4, 6, 1, 3, 5, 2, 5, 1, 4, 1, 4, 1, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 3, 4, 6, 2, 4, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 6, 1, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 3, 2, 6, 1, 2, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 6, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 2, 3, 4, 5, 6, 2, 3, 4, 1, 2, 3, 4, 5, 6, 1, 4, 1, 2, 3, 4, 5, 4, 6, 1, 2, 3, 4, 5, 6, 2, 5, 6, 1, 2, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 1, 3, 4, 5, 6, 1, 2, 3, 4, 5, 6, 4, 6, 1, 2, 3, 4, 5, 6, 3, 5, 1, 2, 3, 4, 5, 6, 2, 6, 3, 1, 2, 6, 1, 2, 3, 4, 5, 6, 1, 2, 4, 6, 1, 2, 4, 5], \"Freq\": [0.17224366962909698, 0.31271424889564514, 0.11471763253211975, 0.07792771607637405, 0.15986888110637665, 0.16221006214618683, 0.999116837978363, 1.000278353691101, 0.9993545413017273, 0.9749468564987183, 0.023779191076755524, 0.5449711084365845, 0.0440380685031414, 0.27523791790008545, 0.013211420737206936, 0.12220563739538193, 0.002739357529208064, 0.7533233165740967, 0.2246273159980774, 0.008218072354793549, 0.010957430116832256, 0.005271815694868565, 0.02108726277947426, 0.005271815694868565, 0.9647422432899475, 0.0012101618340238929, 0.13311780989170074, 0.05990301072597504, 0.15853120386600494, 0.6456213593482971, 0.0018152428092435002, 0.7411605715751648, 0.020976243540644646, 0.024472283199429512, 0.10837725549936295, 0.09439309686422348, 0.006992081180214882, 0.12277592718601227, 0.2282678633928299, 0.26164382696151733, 0.16926389932632446, 0.1305239200592041, 0.08820794522762299, 0.04102364555001259, 0.9572184085845947, 0.06899053603410721, 0.05749211087822914, 0.8738800883293152, 0.005147114861756563, 0.005147114861756563, 0.010294229723513126, 0.005147114861756563, 0.03602980449795723, 0.9419220089912415, 0.007633680943399668, 0.05343576893210411, 0.007633680943399668, 0.0992378517985344, 0.8358880877494812, 0.15728873014450073, 0.07794839888811111, 0.27189144492149353, 0.47279414534568787, 0.008815593086183071, 0.011135485954582691, 0.003156243357807398, 0.9588667154312134, 0.0050499895587563515, 0.0025249947793781757, 0.0025249947793781757, 0.02777494117617607, 0.011712913401424885, 0.026354055851697922, 0.951674222946167, 0.002928228350356221, 0.005856456700712442, 0.40820562839508057, 0.03928016498684883, 0.13247427344322205, 0.25955715775489807, 0.09704510867595673, 0.06392654031515121, 0.7052756547927856, 0.010333709418773651, 0.08266967535018921, 0.16275592148303986, 0.03616798296570778, 0.0051668547093868256, 0.0019318904960528016, 0.5583163499832153, 0.0038637809921056032, 0.015455123968422413, 0.42115211486816406, 1.0018998384475708, 0.9993013143539429, 0.009568367153406143, 0.06506489962339401, 0.04401449114084244, 0.02679142914712429, 0.7539873719215393, 0.09759734570980072, 0.9867714643478394, 0.007590549532324076, 1.0019007921218872, 0.5805969834327698, 0.1976625919342041, 0.14042894542217255, 0.02714172936975956, 0.04425282031297684, 0.010030639357864857, 0.11904473602771759, 0.15971219539642334, 0.07468023896217346, 0.148621067404747, 0.4318144619464874, 0.06654674559831619, 0.9699856638908386, 0.032332856208086014, 0.9840747714042664, 0.009462256915867329, 0.9304530024528503, 0.028195545077323914, 0.028195545077323914, 0.005639109294861555, 0.2689633071422577, 0.017234543338418007, 0.02872423827648163, 0.6470787525177002, 0.005744847469031811, 0.03185779228806496, 0.225991353392601, 0.08110732585191727, 0.11056938767433167, 0.29981982707977295, 0.1975691318511963, 0.08526667207479477, 0.08676957339048386, 0.0020178970880806446, 0.0020178970880806446, 0.0020178970880806446, 0.9019999504089355, 0.004035794176161289, 0.13775339722633362, 0.12664425373077393, 0.059989381581544876, 0.03777109086513519, 0.5621227025985718, 0.07443127036094666, 0.013332470320165157, 0.09999353438615799, 0.031109098345041275, 0.06888443231582642, 0.011110392399132252, 0.777727484703064, 1.000709891319275, 0.3542121648788452, 0.07374764233827591, 0.021975308656692505, 0.03165934234857559, 0.12477505207061768, 0.3936932384967804, 0.0027703328523784876, 0.005540665704756975, 0.8920471668243408, 0.09973198175430298, 0.11045172810554504, 0.8183468580245972, 0.06024639680981636, 0.010041066445410252, 0.0061590722762048244, 0.02287655510008335, 0.9150621891021729, 0.012318144552409649, 0.03343496471643448, 0.009678542613983154, 0.002956185257062316, 0.0024634876754134893, 0.9592821598052979, 0.004926975350826979, 0.01527362409979105, 0.014780926518142223, 0.060731541365385056, 0.9048999547958374, 0.030365770682692528, 0.022183755412697792, 0.9760852456092834, 0.9974539279937744, 0.03691200166940689, 0.11952457576990128, 0.03339657187461853, 0.03163885697722435, 0.750544011592865, 0.02812342904508114, 0.016150863841176033, 0.016150863841176033, 0.9690517783164978, 0.9985388517379761, 0.055480558425188065, 0.29887914657592773, 0.0900813415646553, 0.03519734367728233, 0.4223681390285492, 0.0978366881608963, 0.22082370519638062, 0.13460569083690643, 0.1310865879058838, 0.04486856237053871, 0.12932702898979187, 0.33959344029426575, 0.008754158392548561, 0.008754158392548561, 0.9804657101631165, 0.9762266278266907, 0.02638450264930725, 0.962171733379364, 0.03356413170695305, 0.10520398616790771, 0.061368994414806366, 0.2036641389131546, 0.44914010167121887, 0.05597391724586487, 0.12408675998449326, 0.13576549291610718, 0.04390022158622742, 0.05690769478678703, 0.733296275138855, 0.008129670284688473, 0.02195011079311371, 0.13965673744678497, 0.0017678068252280354, 0.003535613650456071, 0.8397082090377808, 0.003535613650456071, 0.010606841184198856, 0.03876611217856407, 0.0038766113575547934, 0.023259667679667473, 0.9084192514419556, 0.0025844075717031956, 0.024551872164011, 0.005816816817969084, 0.23558108508586884, 0.002908408408984542, 0.037809308618307114, 0.017450449988245964, 0.6980180144309998, 0.9847114682197571, 0.0034191368613392115, 0.013676547445356846, 0.01302536204457283, 0.9860199093818665, 0.7475721836090088, 0.0033523417077958584, 0.020114049315452576, 0.0033523417077958584, 0.18102644383907318, 0.04693278297781944, 0.010997454635798931, 0.9677760004997253, 0.010997454635798931, 0.8409048914909363, 0.003446331713348627, 0.013785326853394508, 0.006892663426697254, 0.058587636798620224, 0.07926562428474426, 0.9970696568489075, 0.017602141946554184, 0.017602141946554184, 0.017602141946554184, 0.9505156874656677, 0.017602141946554184, 0.05811840295791626, 0.21548515558242798, 0.154237300157547, 0.025035619735717773, 0.3004274368286133, 0.2467796802520752, 0.08546655625104904, 0.20851179957389832, 0.16527968645095825, 0.041569337248802185, 0.19653981924057007, 0.30262476205825806, 0.08068937063217163, 0.19903379678726196, 0.03227575123310089, 0.10973754525184631, 0.5519153475761414, 0.025820599868893623, 0.0017481634858995676, 0.7971625328063965, 0.04778313264250755, 0.029718779027462006, 0.005827211309224367, 0.11829239130020142, 0.9074867367744446, 0.005398785229772329, 0.006871181074529886, 0.06331302970647812, 0.01668715476989746, 0.9728918671607971, 0.021314239129424095, 0.0006875561084598303, 0.005500448867678642, 0.8846365213394165, 0.08147968351840973, 0.011639954522252083, 0.023279909044504166, 0.15366943180561066, 0.22059601545333862, 0.14207878708839417, 0.1540433168411255, 0.19517140090465546, 0.13422706723213196, 0.16308653354644775, 0.0082725053653121, 0.7587069272994995, 0.04136252775788307, 0.015363224782049656, 0.012999651953577995, 0.02785227820277214, 0.006963069550693035, 0.9191251993179321, 0.03481534868478775, 0.006963069550693035, 0.0402245931327343, 0.04214005172252655, 0.009577284567058086, 0.8657864928245544, 0.007661827374249697, 0.03256276622414589, 0.042525433003902435, 0.9568222165107727, 0.04094861447811127, 0.013649538159370422, 0.9418181777000427, 0.2930186092853546, 0.3354083001613617, 0.044509157538414, 0.1891639232635498, 0.09325728565454483, 0.044509157538414, 0.07360166311264038, 0.0796511098742485, 0.019156597554683685, 0.02823077328503132, 0.4022885262966156, 0.397247314453125, 0.009538404643535614, 0.8775331974029541, 0.019076809287071228, 0.006358936429023743, 0.034974150359630585, 0.057230427861213684, 0.9764876365661621, 0.02900458313524723, 0.8673637509346008, 0.05421023443341255, 0.07228031009435654, 0.009035038761794567, 0.00527592608705163, 0.9918740391731262, 1.0013480186462402, 0.9935201406478882, 0.025703629478812218, 0.9253306984901428, 0.025703629478812218, 1.001399278640747, 0.04433880001306534, 0.004926533438265324, 0.8473637700080872, 0.10345720499753952, 0.09209659695625305, 0.008008399046957493, 0.5886173844337463, 0.06106404587626457, 0.15316064655780792, 0.09810288995504379, 0.058262962847948074, 0.013109167106449604, 0.8477261066436768, 0.06554583460092545, 0.013109167106449604, 0.0014565740711987019, 0.04910438880324364, 0.18679916858673096, 0.08454054594039917, 0.033917464315891266, 0.1473131626844406, 0.4981310963630676, 0.003806191263720393, 0.9972221255302429, 1.000577688217163, 0.028114520013332367, 0.014057260006666183, 0.014057260006666183, 0.9488650560379028, 0.9944730997085571, 0.0540873259305954, 0.9411194324493408, 0.03765784204006195, 0.09989788383245468, 0.07740778475999832, 0.06799332797527313, 0.6924858689308167, 0.025105226784944534, 0.014845219440758228, 0.042414914816617966, 0.14633145928382874, 0.033931929618120193, 0.7083290815353394, 0.05301864072680473, 0.04944024235010147, 0.9455446004867554, 0.1349242925643921, 0.26530569791793823, 0.13356143236160278, 0.2448626160621643, 0.09540101885795593, 0.1258384883403778, 0.013291272334754467, 0.9835541248321533, 0.1253359019756317, 0.8683987259864807, 0.0014172990340739489, 0.08787254244089127, 0.17999698221683502, 0.02976328134536743, 0.6434537768363953, 0.058109261095523834, 0.4879833459854126, 0.0487983338534832, 0.13521204888820648, 0.2185758650302887, 0.06913097202777863, 0.041681911796331406, 0.5330650806427002, 0.23378592729568481, 0.07792864739894867, 0.029015984386205673, 0.10943171381950378, 0.01658056303858757, 0.003198780119419098, 0.003198780119419098, 0.934043824672699, 0.06077682226896286, 0.0162004753947258, 0.5482581853866577, 0.07247581332921982, 0.06394924968481064, 0.2830820083618164, 0.0162004753947258, 0.654209315776825, 0.06062314659357071, 0.04797782748937607, 0.1710837334394455, 0.03942364081740379, 0.02640640176832676, 0.6419697403907776, 0.04542405903339386, 0.08978349715471268, 0.12207715958356857, 0.07381409406661987, 0.02697053551673889, 0.5916247367858887, 0.02912142500281334, 0.15940147638320923, 0.08583156764507294, 0.07356991618871689, 0.06130826100707054, 0.6098639369010925, 0.016754504293203354, 0.13180209696292877, 0.07707071304321289, 0.11393062025308609, 0.05026350915431976, 0.594218909740448, 0.03749142214655876, 0.09634892642498016, 0.14714375138282776, 0.03749142214655876, 0.08707685023546219, 0.9128868579864502, 0.00297034764662385, 0.015346796251833439, 0.05742672085762024, 0.003960463684052229, 0.007425869349390268, 0.01557944342494011, 0.11472135782241821, 0.024077322334051132, 0.0014163129962980747, 0.8101310729980469, 0.03540782630443573, 0.026027537882328033, 0.013013768941164017, 0.9369913935661316, 0.013013768941164017, 0.2993486225605011, 0.1897159367799759, 0.14731891453266144, 0.10363714396953583, 0.13104531168937683, 0.1289040595293045, 0.08348210155963898, 0.24859115481376648, 0.107228122651577, 0.21185901761054993, 0.17030349373817444, 0.17846618592739105, 0.17412522435188293, 0.2708614766597748, 0.11968297511339188, 0.1300314962863922, 0.1948222815990448, 0.11068425327539444, 0.06497257202863693, 0.6738584041595459, 0.0037127183750271797, 0.13365785777568817, 0.11138155311346054, 0.012994514778256416, 0.10114393383264542, 0.05057196691632271, 0.4406985640525818, 0.2733294367790222, 0.08789889514446259, 0.046959683299064636, 0.9842839241027832, 0.010043713264167309, 0.9694879651069641, 0.03658445179462433, 1.0055781602859497, 0.034999001771211624, 0.9659724235534668, 0.815705418586731, 0.0032628218177706003, 0.02936539612710476, 0.13703851401805878, 0.013051287271082401, 0.0032628218177706003, 0.0018560467287898064, 0.07795396447181702, 0.7015856504440308, 0.018560467287898064, 0.12064303457736969, 0.0798100084066391, 0.03575950860977173, 0.010217002592980862, 0.010217002592980862, 0.010217002592980862, 0.9297472834587097, 0.005108501296490431, 0.010665999725461006, 0.0042663998901844025, 0.023465199396014214, 0.9130095839500427, 0.04693039879202843, 0.9616869688034058, 0.03518366813659668, 0.44310900568962097, 0.05811265483498573, 0.12245167046785355, 0.2957518994808197, 0.04565994441509247, 0.03424495831131935, 0.5630906820297241, 0.0910881981253624, 0.20598353445529938, 0.037263352423906326, 0.06210558861494064, 0.04036863148212433, 0.21116195619106293, 0.13916270434856415, 0.12089424580335617, 0.3632200360298157, 0.11337193846702576, 0.05265616253018379, 0.932093620300293, 0.021427439525723457, 0.010713719762861729, 0.010713719762861729, 0.010713719762861729, 0.010713719762861729, 0.018400417640805244, 0.2774216830730438, 0.5633358955383301, 0.012738751247525215, 0.10332542657852173, 0.02547750249505043, 0.8054665327072144, 0.19312356412410736, 0.9985107183456421, 0.22189553081989288, 0.13754482567310333, 0.1763005554676056, 0.19453854858875275, 0.1778203845024109, 0.09194985777139664, 0.0928078293800354, 0.1308506727218628, 0.010451332665979862, 0.7295029759407043, 0.00794301275163889, 0.02884567715227604, 0.07756596058607101, 0.919710636138916, 0.009744537062942982, 0.08039243519306183, 0.0012180671328678727, 0.8977155089378357, 0.009744537062942982, 1.0009300708770752, 0.02193533442914486, 0.0073117781430482864, 0.1718267798423767, 0.0073117781430482864, 0.2970409691333771, 0.49445897340774536, 0.14491906762123108, 0.054460033774375916, 0.09138208627700806, 0.6599817276000977, 0.019384078681468964, 0.030460696667432785, 0.9870517253875732, 0.004129923414438963, 0.012389770708978176, 1.000746726989746, 0.01787792518734932, 0.9594486951828003, 0.02383723482489586, 0.9453923106193542, 0.012120414525270462, 0.036361243575811386, 0.08428464829921722, 0.3978235423564911, 0.12541556358337402, 0.1119300127029419, 0.13080976903438568, 0.14968954026699066, 0.5102623105049133, 0.037279438227415085, 0.15552516281604767, 0.07514137029647827, 0.08970364928245544, 0.13164301216602325, 0.018003318458795547, 0.39007189869880676, 0.01200221199542284, 0.0017146016471087933, 0.49380528926849365, 0.0848727822303772, 0.9896215200424194, 0.011826097033917904, 0.03547829017043114, 0.011826097033917904, 0.9460877180099487, 0.0031963514629751444, 0.4130396246910095, 0.01527145691215992, 0.024505360051989555, 0.02379506081342697, 0.5199398398399353, 0.07187537103891373, 0.02395845577120781, 0.06388921290636063, 0.8385459780693054, 0.7908141016960144, 0.14674900472164154, 0.008152722381055355, 0.04891633614897728, 0.03636333346366882, 0.963628351688385, 0.059732623398303986, 0.12042868137359619, 0.07803778350353241, 0.04046403616666794, 0.5819113850593567, 0.12042868137359619, 0.2578684687614441, 0.3512696325778961, 0.27167558670043945, 0.013807130046188831, 0.0824366882443428, 0.02314724773168564, 0.018383724614977837, 0.9927210807800293, 0.8678195476531982, 0.10847744345664978, 0.0380668006837368, 0.4475732743740082, 0.1930255889892578, 0.14803755283355713, 0.04998670890927315, 0.12265969067811966, 0.223597913980484, 0.06723573803901672, 0.03361786901950836, 0.18216194212436676, 0.15479856729507446, 0.33930593729019165, 0.07198909670114517, 0.13656754791736603, 0.020114600658416748, 0.023290591314435005, 0.7103630304336548, 0.035994548350572586, 0.9288439750671387, 0.07024870812892914, 0.058369316160678864, 0.09172321110963821, 0.020846184343099594, 0.0020846184343099594, 0.7567164897918701, 0.06879241019487381, 0.9982402920722961, 0.00534485187381506, 0.994142472743988, 0.0019175668712705374, 0.6500551700592041, 0.024928368628025055, 0.2128499150276184, 0.1016310453414917, 0.00958783458918333, 0.113118477165699, 0.07311315834522247, 0.038625821471214294, 0.7145776748657227, 0.009656455367803574, 0.051041264086961746, 0.016296809539198875, 0.9615117311477661, 0.07052044570446014, 0.013470198027789593, 0.13390961289405823, 0.6679633259773254, 0.014658745378255844, 0.099441759288311, 0.24960604310035706, 0.1031704992055893, 0.1554689109325409, 0.288592129945755, 0.10649857670068741, 0.09698978066444397, 0.06734839826822281, 0.005612366832792759, 0.892366349697113, 0.033674199134111404, 0.005612366832792759, 0.09853361546993256, 0.0961156114935875, 0.03203853592276573, 0.11243712902069092, 0.07918959110975266, 0.5821341872215271, 0.16218358278274536, 0.04177455976605415, 0.06634782999753952, 0.009829308837652206, 0.0638905018568039, 0.6561063528060913, 0.19778671860694885, 0.23959527909755707, 0.16884231567382812, 0.17326436936855316, 0.13949590921401978, 0.08120511472225189, 0.748984694480896, 0.0028696730732917786, 0.008609019219875336, 0.07461149990558624, 0.0028696730732917786, 0.1607016921043396, 0.0020611314103007317, 0.16695165634155273, 0.686356782913208, 0.14427919685840607, 0.0014801883371546865, 0.8281653523445129, 0.018502354621887207, 0.03182404860854149, 0.11989524960517883, 0.028523996472358704, 0.36161068081855774, 0.11777650564908981, 0.07683076709508896, 0.27971920371055603, 0.13525895774364471, 0.9642962217330933, 0.017219575121998787, 0.052998289465904236, 0.19790500402450562, 0.06708644330501556, 0.07849113643169403, 0.3387865424156189, 0.2656623125076294, 0.21930652856826782, 0.03177076578140259, 0.07633809000253677, 0.4893580377101898, 0.0833982601761818, 0.09928364306688309, 0.010809770785272121, 0.9728794097900391, 0.010809770785272121, 0.8453587889671326, 0.013903927057981491, 0.011123142205178738, 0.08064277470111847, 0.005561571102589369, 0.04449256882071495, 0.026017367839813232, 0.9691469669342041, 0.04366380721330643, 0.9460492134094238, 0.9987530708312988, 0.09563400596380234, 0.35810399055480957, 0.018847577273845673, 0.4551340937614441, 0.017451461404561996, 0.05584467574954033, 0.10008430480957031, 0.09458516538143158, 0.035194482654333115, 0.7016899585723877, 0.004399310331791639, 0.06269016861915588, 0.1081724539399147, 0.019667718559503555, 0.034418508410453796, 0.8112934231758118, 0.014750788919627666, 0.013111812993884087, 0.0344272181391716, 0.011475740000605583, 0.011475740000605583, 0.022951480001211166, 0.011475740000605583, 0.9065834283828735, 0.021845757961273193, 0.10267505794763565, 0.4893449544906616, 0.10158277302980423, 0.20753468573093414, 0.0775524377822876, 0.32322579622268677, 0.052414994686841965, 0.39781635999679565, 0.08870229870080948, 0.08803030848503113, 0.049055058509111404, 0.9384062886238098, 0.05141952261328697, 0.7922321557998657, 0.02685532718896866, 0.17455962300300598, 0.006713831797242165, 0.21861089766025543, 0.02363361045718193, 0.3485957384109497, 0.10339704155921936, 0.2788766026496887, 0.027178650721907616, 0.007988117635250092, 0.6350553035736084, 0.05059140920639038, 0.182395339012146, 0.07721846550703049, 0.04526599869132042, 0.045283328741788864, 0.01531642023473978, 0.603999674320221, 0.07991176098585129, 0.22774851322174072, 0.0273031834512949, 0.8346768617630005, 0.0662441998720169, 0.0662441998720169, 0.013248839415609837, 0.013248839415609837, 1.0005249977111816, 0.05023711174726486, 0.011417524889111519, 0.06165463477373123, 0.806077241897583, 0.07078865170478821, 0.1454283744096756, 0.08647092431783676, 0.6511522531509399, 0.028823642060160637, 0.032754138112068176, 0.05633711814880371, 0.10754676163196564, 0.008962230756878853, 0.8827796578407288, 0.9545912742614746, 0.04545672610402107, 0.01515224203467369, 0.0512138232588768, 0.09655064344406128, 0.055411674082279205, 0.1578393131494522, 0.15951846539974213, 0.47939494252204895, 0.0232448298484087, 0.09879052639007568, 0.005811207462102175, 0.8658698797225952, 0.9961145520210266, 0.032962385565042496, 0.06262852996587753, 0.013184954412281513, 0.023073669523000717, 0.009888716042041779, 0.8603182435035706, 0.007398271933197975, 0.007398271933197975, 0.007398271933197975, 0.9765718579292297, 0.0926758274435997, 0.029656264930963516, 0.09638285636901855, 0.7821840047836304, 0.09336380660533905, 0.2240731418132782, 0.04481462761759758, 0.0662882998585701, 0.259084552526474, 0.3123019337654114, 0.03594614937901497, 0.7714596390724182, 0.011060353368520737, 0.024885794147849083, 0.052536677569150925, 0.10230826586484909, 0.020855018869042397, 0.7931324243545532, 0.0028876180294901133, 0.0760406106710434, 0.03689734265208244, 0.06994453072547913, 0.025421462953090668, 0.7513454556465149, 0.22314395010471344, 0.04595421627163887, 0.9282751679420471, 0.022977108135819435, 0.00930350087583065, 0.12360365688800812, 0.04585297033190727, 0.0232587531208992, 0.7775068879127502, 0.019936073571443558, 0.13712573051452637, 0.06606462597846985, 0.08938155323266983, 0.4829934537410736, 0.05773714929819107, 0.1665494740009308, 0.024162955582141876, 0.006040738895535469, 0.010571292601525784, 0.9166821241378784, 0.040774986147880554, 0.9821286201477051, 0.007794671691954136, 0.060773611068725586, 0.010128934867680073, 0.9014752507209778, 0.0033763116225600243, 0.027010492980480194, 0.020702315494418144, 0.9730088114738464, 0.013913951814174652, 0.9739766120910645, 0.06791950017213821, 0.004244968760758638, 0.014149895869195461, 0.7754142880439758, 0.0028299791738390923, 0.13442400097846985, 0.1189168393611908, 0.21815377473831177, 0.12561637163162231, 0.17753781378269196, 0.17460677027702332, 0.18549351394176483, 0.9946816563606262, 0.019379084929823875, 0.012239422649145126, 0.037738218903541565, 0.02243894152343273, 0.698667049407959, 0.20909012854099274, 0.0448116771876812, 0.1988518089056015, 0.1155301034450531, 0.4817255139350891, 0.08822298794984818, 0.07141860574483871, 0.04807016998529434, 0.03685379773378372, 0.12978945672512054, 0.7258595824241638, 0.012818712741136551, 0.04807016998529434, 0.12953849136829376, 0.24157176911830902, 0.01750520057976246, 0.5279568433761597, 0.06932059675455093, 0.014004160650074482, 0.05660570040345192, 0.0062895226292312145, 0.9182702898979187, 0.018868567422032356, 0.33115339279174805, 0.04972273111343384, 0.06911459565162659, 0.44800180196762085, 0.0621534138917923, 0.03977818414568901, 0.9725928902626038, 0.02506682649254799, 0.07878223061561584, 0.12700873613357544, 0.05743003636598587, 0.6446153521537781, 0.01398936752229929, 0.07804594933986664, 0.03997223824262619, 0.03536005690693855, 0.07840708643198013, 0.7502481937408447, 0.007686969358474016, 0.08763144910335541, 0.9010573625564575, 0.02371203526854515, 0.07113610953092575, 0.18197418749332428, 0.18016350269317627, 0.08736571669578552, 0.29695290327072144, 0.17925815284252167, 0.07469090074300766, 0.010321283712983131, 0.010321283712983131, 0.9289155006408691, 0.041285134851932526, 0.010321283712983131, 0.04982796683907509, 0.21290132403373718, 0.047563061118125916, 0.002264907583594322, 0.6862670183181763, 0.07775518298149109, 0.9157832860946655, 0.14347711205482483, 0.37653252482414246, 0.15865987539291382, 0.11766640841960907, 0.0645267441868782, 0.13968141376972198, 0.10310225188732147, 0.1335485577583313, 0.12801286578178406, 0.1861376315355301, 0.188213512301445, 0.26086947321891785, 0.7943617701530457, 0.08032871782779694, 0.017850825563073158, 0.10710495710372925, 0.16889888048171997, 0.11363226920366287, 0.11208274215459824, 0.32643452286720276, 0.18336117267608643, 0.09503789991140366, 0.048376478254795074, 0.020156865939497948, 0.8143373727798462, 0.024188239127397537, 0.09272158145904541, 0.0040313731878995895, 0.001395710278302431, 0.005582841113209724, 0.0069785513915121555, 0.9141902327537537, 0.07118122279644012, 0.010302357375621796, 0.06556045264005661, 0.053384941071271896, 0.012175513431429863, 0.6209511756896973, 0.2378907948732376, 0.00891487393528223, 0.005943248979747295, 0.7221047878265381, 0.18424072861671448, 0.02377299591898918, 0.05348924174904823, 0.0050722104497253895, 0.9840088486671448, 0.010144420899450779, 0.011022794991731644, 0.9589831829071045, 0.03306838497519493, 0.9949347972869873, 0.0033956817351281643, 0.13023729622364044, 0.04728616029024124, 0.46404552459716797, 0.21559283137321472, 0.06291463226079941, 0.08014602959156036, 0.17145980894565582, 0.5048816204071045, 0.06848394125699997, 0.23244550824165344, 0.02149496041238308, 0.0009997655870392919, 0.012740548700094223, 0.9937627911567688, 0.9907619953155518, 0.01435886975377798, 0.029072556644678116, 0.17064327001571655, 0.02022438682615757, 0.003792072646319866, 0.7129096388816833, 0.06446523219347, 0.03232245147228241, 0.11918903887271881, 0.026261990889906883, 0.010100766085088253, 0.7292752861976624, 0.08484643697738647, 0.16104881465435028, 0.2044776976108551, 0.14005817472934723, 0.1483820527791977, 0.2167825549840927, 0.12920095026493073, 0.011866669170558453, 0.9493335485458374, 0.011866669170558453, 0.023733338341116905, 0.031877048313617706, 0.9456858038902283, 0.021251367405056953, 0.2828962802886963, 0.13245432078838348, 0.3902769386768341, 0.07086033374071121, 0.04687683656811714, 0.0774012878537178, 0.4667763411998749, 0.18040511012077332, 0.1077176183462143, 0.10946912318468094, 0.12610842287540436, 0.009633283130824566, 0.523534893989563, 0.10692368447780609, 0.16038553416728973, 0.09975197911262512, 0.052157897502183914, 0.05737368389964104, 0.16570931673049927, 0.20369943976402283, 0.15087507665157318, 0.032562967389822006, 0.3346749246120453, 0.11216133087873459, 0.065658338367939, 0.8535584211349487, 0.049243755638599396, 0.004103646147996187, 0.008207292295992374, 0.020518232136964798, 0.1674889326095581, 0.13026916980743408, 0.22080373764038086, 0.23036015033721924, 0.19263742864131927, 0.05834449455142021, 0.22341488301753998, 0.03505894914269447, 0.068743035197258, 0.6179999113082886, 0.04262068495154381, 0.011686316691339016, 0.21918374300003052, 0.14470064640045166, 0.10827939212322235, 0.3182757794857025, 0.15093490481376648, 0.05906148627400398, 0.005810600705444813, 0.005810600705444813, 0.9355067014694214, 0.05229540541768074, 0.8781834840774536, 0.1205349862575531, 0.011277707293629646, 0.00375923584215343, 0.9097350835800171, 0.03007388673722744, 0.041351594030857086, 0.9986666440963745, 0.0028697317466139793, 0.04760194942355156, 0.04760194942355156, 0.025631818920373917, 0.17759189009666443, 0.690228283405304, 0.010985065251588821, 0.24472784996032715, 0.07295270264148712, 0.010347900912165642, 0.569134533405304, 0.043461184948682785, 0.05950042977929115, 0.059439267963171005, 0.22380703687667847, 0.08733933418989182, 0.08370019495487213, 0.3354072868824005, 0.2098570019006729, 0.006123195867985487, 0.9552186131477356, 0.00204106536693871, 0.01632852293550968, 0.012246391735970974, 0.00816426146775484, 0.017108233645558357, 0.9523583650588989, 0.0057027447037398815, 0.017108233645558357, 1.0005124807357788, 0.6459575891494751, 0.01790687069296837, 0.0624556690454483, 0.13146263360977173, 0.05022658780217171, 0.09259162098169327, 0.8869467973709106, 0.019709927961230278, 0.019709927961230278, 0.05912978574633598, 0.010705254040658474, 0.02319471538066864, 0.0035684178583323956, 0.9581202268600464, 0.0035684178583323956, 0.00878923013806343, 0.030762305483222008, 0.004394615069031715, 0.9492368698120117, 0.004394615069031715, 0.2696923613548279, 0.06486272066831589, 0.10668209940195084, 0.2517697513103485, 0.012801852077245712, 0.29358914494514465, 0.04145064949989319, 0.4599427580833435, 0.07094437628984451, 0.2646464407444, 0.1490629017353058, 0.013551173731684685, 0.005778089631348848, 0.028890447691082954, 0.011556179262697697, 0.936050534248352, 0.017334269359707832, 0.9981920719146729, 0.0109052499756217, 0.2296334058046341, 0.12276195734739304, 0.038947321474552155, 0.31936803460121155, 0.27855125069618225, 0.9047560095787048, 0.04971186816692352, 0.0397694930434227, 0.009942373260855675, 0.04636632278561592, 0.25454163551330566, 0.007570012006908655, 0.6339884996414185, 0.04636632278561592, 0.011355018243193626, 0.6225662231445312, 0.06309165805578232, 0.051957834511995316, 0.051957834511995316, 0.1540178656578064, 0.05474129319190979, 0.9714892506599426, 0.029364915564656258, 0.9983887672424316, 0.09844690561294556, 0.9044809341430664, 1.0013818740844727, 0.08383923768997192, 0.8803119659423828, 0.04191961884498596, 0.02786417305469513, 0.011145669035613537, 0.12260235846042633, 0.8414980173110962, 0.16577205061912537, 0.032954681664705276, 0.16477341949939728, 0.034951936453580856, 0.5492447018623352, 0.05292721837759018, 0.004442812874913216, 0.19770517945289612, 0.035542502999305725, 0.013328438624739647, 0.09774188697338104, 0.6508721113204956, 0.6509761810302734, 0.04418390616774559, 0.04344750568270683, 0.055229879915714264, 0.12076933681964874, 0.08615861088037491, 0.06513115763664246, 0.0355260893702507, 0.001973671605810523, 0.06315749138593674, 0.053289130330085754, 0.783547580242157, 0.01724587194621563, 0.17501366138458252, 0.32000672817230225, 0.15649032592773438, 0.3046770691871643, 0.02618817612528801, 0.2782728970050812, 0.11930625885725021, 0.0435614138841629, 0.410257488489151, 0.0695682242512703, 0.07932078093290329, 0.015606211498379707, 0.9831913113594055, 0.9814704656600952, 0.02088235132396221, 0.045551180839538574, 0.011387795209884644, 0.9337992072105408, 1.0002968311309814, 0.7997531890869141, 0.012496143579483032, 0.0374884307384491, 0.04998457431793213, 0.09996914863586426, 0.039056286215782166, 0.07468658685684204, 0.02055594138801098, 0.3131355047225952, 0.05550104007124901, 0.498138964176178, 0.3963184952735901, 0.24117055535316467, 0.07987814396619797, 0.08602261543273926, 0.16436465084552765, 0.03302654251456261, 0.8584698438644409, 0.007875869981944561, 0.05513108894228935, 0.015751739963889122, 0.015751739963889122, 0.051193155348300934, 0.9873252511024475, 0.011615591123700142, 0.009189222007989883, 0.06432455778121948, 0.009189222007989883, 0.009189222007989883, 0.8959491848945618, 0.009189222007989883, 0.9974948167800903, 0.09522109478712082, 0.08541291207075119, 0.13690586388111115, 0.4973565340042114, 0.10012518614530563, 0.08500424027442932, 0.06668855994939804, 0.22739706933498383, 0.053569499403238297, 0.06231554225087166, 0.16289500892162323, 0.42636948823928833, 1.0004477500915527, 1.0006263256072998, 0.06489957123994827, 0.09117598086595535, 0.45904573798179626, 0.1278996467590332, 0.09624131768941879, 0.16082429885864258, 0.21224886178970337, 0.04886304959654808, 0.10688792169094086, 0.20970392227172852, 0.037156276404857635, 0.38479650020599365, 0.1171264573931694, 0.07630965858697891, 0.09405609220266342, 0.1597178876399994, 0.021295718848705292, 0.5323929786682129, 0.025908611714839935, 0.09553800523281097, 0.14411665499210358, 0.008096440695226192, 0.22346177697181702, 0.5019793510437012, 0.00455492315813899, 0.9610888361930847, 0.00455492315813899, 0.02277461625635624, 0.00455492315813899, 0.09852580726146698, 0.15246731042861938, 0.2322787195444107, 0.12274444103240967, 0.3808930814266205, 0.01321016438305378, 0.05859292671084404, 0.3572540879249573, 0.07893769443035126, 0.11881343275308609, 0.11881343275308609, 0.26733022928237915, 0.04597065970301628, 0.006567236967384815, 0.006567236967384815, 0.9325476288795471, 0.47600382566452026, 0.04247259348630905, 0.08701702207326889, 0.1864650398492813, 0.15849529206752777, 0.050241969525814056, 0.007167683448642492, 0.017919208854436874, 0.02150304988026619, 0.9461342096328735, 0.007167683448642492, 0.12795281410217285, 0.09667545557022095, 0.06539810448884964, 0.6670606136322021, 0.03582678735256195, 0.006824149750173092, 0.06580725312232971, 0.10369627922773361, 0.8245848417282104, 0.0029912388417869806, 0.003988318610936403, 0.011605947278439999, 0.06576703488826752, 0.9207385182380676, 0.003868649248033762, 0.04981650412082672, 0.007116643246263266, 0.9322802424430847, 0.9395492076873779, 0.05872182548046112, 0.019881457090377808, 0.9741913676261902, 0.005918886046856642, 0.9884539246559143, 0.0417848601937294, 0.0417848601937294, 0.9192668795585632, 0.008245334960520267, 0.039577607065439224, 0.8542166948318481, 0.0032981340773403645, 0.08245334774255753, 0.011543468572199345, 0.9211613535881042, 0.04683871194720268, 0.007806451991200447, 0.015612903982400894, 0.007806451991200447, 0.030593857169151306, 0.0017996386159211397, 0.6424710154533386, 0.1601678431034088, 0.008998192846775055, 0.15836820006370544, 0.9508393406867981, 0.013392103835940361, 0.026784207671880722, 0.929110586643219, 0.06520073860883713, 0.08504810184240341, 0.022985974326729774, 0.009194389916956425, 0.1471102386713028, 0.022985974326729774, 0.7148637771606445, 0.127375990152359, 0.026353655382990837, 0.008784551173448563, 0.021961377933621407, 0.017569102346897125, 0.7993941903114319, 0.09602124243974686, 0.00800176989287138, 0.840185821056366, 0.04801062121987343, 0.00800176989287138, 0.056738462299108505, 0.35095956921577454, 0.016963046044111252, 0.028076766058802605, 0.4480583965778351, 0.09943854808807373, 0.1994386464357376, 0.20194730162620544, 0.04452875256538391, 0.1442480832338333, 0.16808035969734192, 0.2414587289094925, 1.0002562999725342, 0.9993690252304077, 0.0314190611243248, 0.9739909172058105, 0.2142629325389862, 0.12279105186462402, 0.12328818440437317, 0.3166716694831848, 0.12527669966220856, 0.09793456643819809, 0.2774309515953064, 0.09905251115560532, 0.09107793867588043, 0.04365025833249092, 0.4020860195159912, 0.08646108955144882, 0.0032881004735827446, 0.636247456073761, 0.016440503299236298, 0.0016440502367913723, 0.2844206988811493, 0.05754175782203674, 0.9994612336158752, 0.9663954973220825, 0.032213181257247925, 0.9667221903800964, 0.03101782500743866, 0.0711231455206871, 0.0025707161985337734, 0.0702662393450737, 0.003427621442824602, 0.5946923494338989, 0.2579285204410553, 0.01804584451019764, 0.09351028501987457, 0.045934878289699554, 0.003281062701717019, 0.8071414232254028, 0.03281062841415405, 0.003157480387017131, 0.06630709022283554, 0.047362204641103745, 0.8809370398521423, 0.8038604855537415, 0.04394092783331871, 0.007754281163215637, 0.0827123299241066, 0.0620342493057251, 0.007215183228254318, 0.7131006121635437, 0.05170881375670433, 0.03126579523086548, 0.06253159046173096, 0.1340821534395218, 0.007284869439899921, 0.27682504057884216, 0.007284869439899921, 0.0024282897356897593, 0.046137504279613495, 0.6604948043823242, 0.09732769429683685, 0.04747692123055458, 0.12937460839748383, 0.021364614367485046, 0.6872284412384033, 0.016616923734545708, 0.07001131772994995, 0.0058342763222754, 0.0058342763222754, 0.8868100047111511, 0.029171381145715714, 0.056300509721040726, 0.8507632613182068, 0.09383418411016464, 0.1784139722585678, 0.11914843320846558, 0.07346457988023758, 0.12470457702875137, 0.361149400472641, 0.143842414021492, 0.01911649852991104, 0.9813135862350464, 0.8152223825454712, 0.02356133982539177, 0.0329858772456646, 0.0659717544913292, 0.06125948578119278, 0.9430326819419861, 0.03627048805356026, 0.00472654914483428, 0.7116832733154297, 0.005401770584285259, 0.017555754631757736, 0.24713100492954254, 0.014179647900164127, 0.9658951759338379, 0.008624063804745674, 0.0344962552189827, 0.31092342734336853, 0.12554779648780823, 0.0983533263206482, 0.25925391912460327, 0.1731381118297577, 0.03308660164475441, 0.3681176006793976, 0.01966206729412079, 0.09066397696733475, 0.08520229160785675, 0.3872334957122803, 0.04915516823530197, 0.7860391736030579, 0.017212536185979843, 0.045900098979473114, 0.05737512186169624, 0.09180019795894623, 0.761416494846344, 0.013596722856163979, 0.04985465109348297, 0.14163252711296082, 0.01812896318733692, 0.01586284302175045, 0.02862280048429966, 0.9731751680374146, 0.11764448136091232, 0.11025618016719818, 0.10855118930339813, 0.2546122074127197, 0.17106758058071136, 0.23756228387355804, 0.01664949394762516, 0.9823201298713684, 0.00724688870832324, 0.19566598534584045, 0.00241562956944108, 0.012078147381544113, 0.01932503655552864, 0.7633389234542847, 0.009686838835477829, 0.9880574941635132, 0.9977560043334961, 0.8110895156860352, 0.15449324250221252, 0.03862331062555313, 0.11703543365001678, 0.2793559432029724, 0.2793559432029724, 0.2305421680212021, 0.02881777100265026, 0.06528107076883316, 0.7947725653648376, 0.14137782156467438, 0.05731533095240593, 0.0038210221100598574, 0.04854954034090042, 0.9345786571502686, 0.018206078559160233, 0.006068692542612553], \"Term\": [\"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"activation_function\", \"actor_critic\", \"admm\", \"adoption\", \"adoption\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversary\", \"adversary\", \"adversary\", \"adversary\", \"adversary\", \"age\", \"age\", \"age\", \"age\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"agent\", \"aggregation\", \"aggregation\", \"aggregation\", \"aggregation\", \"aggregation\", \"aggregation\", \"allows\", \"allows\", \"allows\", \"allows\", \"allows\", \"allows\", \"alternating_minimization\", \"alternating_minimization\", \"analytics\", \"analytics\", \"analytics\", \"anomaly\", \"anomaly\", \"anomaly\", \"anomaly\", \"anomaly\", \"anomaly\", \"anomaly_detection\", \"anomaly_detection\", \"anomaly_detection\", \"anomaly_detection\", \"anomaly_detection\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"arm\", \"arm\", \"arm\", \"arm\", \"arm\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"asymptotic\", \"asymptotic\", \"asymptotic\", \"asymptotic\", \"asymptotic\", \"asymptotic\", \"attack\", \"attack\", \"attack\", \"attack\", \"attack\", \"attacker\", \"attention_mechanism\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"backpropagation\", \"backpropagation\", \"batch_size\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"behavior\", \"best_known\", \"best_known\", \"bias_variance\", \"bias_variance\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bootstrap\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"bound\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"causal\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"channel\", \"cifar\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"classifier\", \"clinical\", \"clinical\", \"clinical\", \"clinical\", \"cloud\", \"cloud\", \"cloud\", \"cloud\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"cluster\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"clustering\", \"cognitive\", \"cognitive\", \"cognitive\", \"cohort\", \"cohort\", \"collective\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community_structure\", \"community_structure\", \"community_structure\", \"company\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"complex\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"compound\", \"compound\", \"compound\", \"concentration_inequality\", \"concentration_inequality\", \"confidence_interval\", \"confidence_interval\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convergence_rate\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convex\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolutional\", \"convolutional\", \"convolutional\", \"convolutional_neural\", \"convolutional_neural\", \"covariates\", \"covariates\", \"covariates\", \"covariates\", \"covariates\", \"covariates\", \"cross_entropy\", \"cross_entropy\", \"cross_entropy\", \"cross_validation\", \"cross_validation\", \"cross_validation\", \"cross_validation\", \"cross_validation\", \"cross_validation\", \"customer\", \"dag\", \"dag\", \"dag\", \"dag\", \"dag\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_learning\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"deep_neural\", \"degree_freedom\", \"degree_freedom\", \"degree_freedom\", \"degree_freedom\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"demonstrate\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density\", \"density_estimation\", \"density_estimation\", \"density_estimation\", \"density_estimation\", \"density_estimation\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent\", \"descent_sgd\", \"descent_sgd\", \"descriptor\", \"descriptor\", \"descriptor\", \"design\", \"design\", \"design\", \"design\", \"design\", \"design\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"device\", \"device\", \"device\", \"device\", \"device\", \"device\", \"diagnostic\", \"diagnostic\", \"diagonal\", \"diagonal\", \"diagonal\", \"diagonal\", \"differential_privacy\", \"differential_privacy\", \"differentially_private\", \"digital\", \"directed_acyclic\", \"directed_acyclic\", \"directed_acyclic\", \"directional\", \"disease\", \"disease\", \"disease\", \"disease\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"divergence\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain_adaptation\", \"domain_adaptation\", \"drive\", \"driving\", \"driving\", \"driving\", \"driving\", \"drug\", \"duration\", \"duration\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"edge\", \"eeg\", \"eeg\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"efficient\", \"electronic_health\", \"electronic_health\", \"embedding_space\", \"embedding_space\", \"embeddings\", \"embeddings\", \"embeddings\", \"embeddings\", \"embeddings\", \"embeddings\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"entity\", \"entity\", \"entity\", \"entity\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimated\", \"estimated\", \"estimated\", \"estimated\", \"estimated\", \"estimated\", \"estimating\", \"estimating\", \"estimating\", \"estimating\", \"estimating\", \"estimating\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"estimator\", \"event\", \"event\", \"event\", \"event\", \"event\", \"event\", \"exact_recovery\", \"exact_recovery\", \"exact_recovery\", \"exact_recovery\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"existing\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"family\", \"family\", \"family\", \"family\", \"family\", \"family\", \"feed_forward\", \"feed_forward\", \"feedforward\", \"feedforward\", \"feedforward_neural\", \"fine_grained\", \"fine_grained\", \"finite_sample\", \"finite_sample\", \"finite_sample\", \"finite_sample\", \"finite_sample\", \"finite_sample\", \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"flow\", \"forecast\", \"forecast\", \"forecast\", \"forecast\", \"forecast\", \"forecast\", \"forecasting\", \"forecasting\", \"forecasting\", \"forecasting\", \"forecasting\", \"fully_connected\", \"fully_connected\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"gaussian_process\", \"general\", \"general\", \"general\", \"general\", \"general\", \"general\", \"generalized_linear\", \"generalized_linear\", \"generalized_linear\", \"generalized_linear\", \"generalized_linear\", \"generalized_linear\", \"generative_model\", \"generative_model\", \"generative_model\", \"generative_model\", \"generative_model\", \"generative_model\", \"generator\", \"generator\", \"give_rise\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient_boosting\", \"gradient_boosting\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"gradually\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"hardware\", \"hardware\", \"hardware\", \"health\", \"healthcare\", \"healthcare\", \"healthcare\", \"hierarchical_clustering\", \"hierarchical_clustering\", \"hierarchical_clustering\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high_dimensional\", \"high_dimensional\", \"high_dimensional\", \"high_dimensional\", \"high_dimensional\", \"high_dimensional\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hypothesis_test\", \"ica\", \"ica\", \"ica\", \"ica\", \"image\", \"image\", \"image\", \"image\", \"image\", \"image\", \"imbalanced\", \"imbalanced\", \"imbalanced\", \"imbalanced\", \"importance_sampling\", \"importance_sampling\", \"importance_sampling\", \"importance_sampling\", \"imputation\", \"imputation\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inform\", \"inform\", \"information_criterion\", \"information_criterion\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interaction\", \"interface\", \"interface\", \"interpretable\", \"interpretable\", \"interpretable\", \"interpretable\", \"interpretable\", \"interpretable\", \"interpreting\", \"intervention\", \"intervention\", \"item\", \"item\", \"item\", \"item\", \"item\", \"item\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration_complexity\", \"iteration_complexity\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"kernel\", \"known\", \"known\", \"known\", \"known\", \"known\", \"known\", \"kullback_leibler\", \"kullback_leibler\", \"kullback_leibler\", \"kullback_leibler\", \"kullback_leibler\", \"label\", \"label\", \"label\", \"label\", \"label\", \"label\", \"labeled\", \"labeled\", \"labeled\", \"labeled\", \"labeled\", \"labeled\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"lasso\", \"latent_space\", \"latent_space\", \"latent_space\", \"latent_space\", \"layer\", \"layer\", \"layer\", \"layer\", \"layer\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learnable\", \"learnable\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear_convergence\", \"linear_convergence\", \"linear_convergence\", \"linear_regression\", \"linear_regression\", \"linear_regression\", \"linear_regression\", \"linear_regression\", \"linear_regression\", \"link_prediction\", \"link_prediction\", \"lipschitz\", \"lipschitz\", \"long_short\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss_function\", \"loss_function\", \"loss_function\", \"loss_function\", \"loss_function\", \"loss_function\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"lower_bound\", \"machine_svm\", \"machine_svm\", \"machine_svm\", \"machine_svm\", \"machine_svm\", \"machine_svm\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean_clustering\", \"mean_clustering\", \"mean_squared\", \"mean_squared\", \"mean_squared\", \"mean_squared\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"measure\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"mild_condition\", \"mild_condition\", \"mild_condition\", \"mild_condition\", \"mild_condition\", \"mini_batch\", \"minimization\", \"minimization\", \"minimization\", \"minimization\", \"minimization\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"modality\", \"modality\", \"modality\", \"mri\", \"mri\", \"mri\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi_label\", \"multi_label\", \"multi_label\", \"multi_label\", \"multi_layer\", \"multi_task\", \"multi_task\", \"multi_task\", \"multi_task\", \"multi_task\", \"multi_task\", \"multi_view\", \"multi_view\", \"multi_view\", \"multi_view\", \"multimodal\", \"multimodal\", \"multimodal\", \"multimodal\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"net\", \"net\", \"net\", \"net\", \"net\", \"net\", \"neural_network\", \"neural_network\", \"neural_network\", \"neural_network\", \"neural_network\", \"neural_network\", \"neuron\", \"neuron\", \"neuron\", \"nmf\", \"nmf\", \"nmf\", \"node\", \"node\", \"node\", \"node\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"non_convex\", \"non_convex\", \"non_convex\", \"non_convex\", \"non_convex\", \"non_smooth\", \"non_smooth\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex\", \"nonconvex_optimization\", \"nonconvex_optimization\", \"nonsmooth\", \"nonsmooth\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"norm\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"novel\", \"number_cluster\", \"object\", \"object\", \"object\", \"object\", \"object\", \"object\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective_function\", \"objective_function\", \"objective_function\", \"objective_function\", \"objective_function\", \"objective_function\", \"online\", \"online\", \"online\", \"online\", \"online\", \"online\", \"opportunity\", \"opportunity\", \"opportunity\", \"opportunity\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal_transport\", \"optimal_transport\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization_problem\", \"optimization_problem\", \"optimization_problem\", \"optimization_problem\", \"optimization_problem\", \"optimization_problem\", \"oracle_inequality\", \"oracle_inequality\", \"oracle_inequality\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"origin\", \"origin\", \"origin\", \"origin\", \"origin\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier\", \"outlier_detection\", \"outlier_detection\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"paper_propose\", \"paper_propose\", \"paper_propose\", \"paper_propose\", \"paper_propose\", \"paper_propose\", \"parameter_tuning\", \"parameter_tuning\", \"parameter_tuning\", \"parameter_tuning\", \"particular\", \"particular\", \"particular\", \"particular\", \"particular\", \"particular\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"partition\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pca\", \"pca\", \"pca\", \"pca\", \"pca\", \"pca\", \"perception\", \"perception\", \"perception\", \"personalized\", \"personalized\", \"personalized\", \"platform\", \"platform\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"policy\", \"pooling\", \"pooling\", \"positive_negative\", \"positive_negative\", \"predict\", \"predict\", \"predict\", \"predict\", \"predict\", \"predict\", \"predicting\", \"predicting\", \"predicting\", \"predicting\", \"predicting\", \"predicting\", \"present\", \"present\", \"present\", \"present\", \"present\", \"present\", \"primal\", \"primal\", \"primal\", \"primal\", \"primal_dual\", \"primal_dual\", \"primal_dual\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"propagation\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"provide\", \"proximal\", \"proximal\", \"proximal\", \"proximal\", \"proximity\", \"proximity\", \"pruning\", \"pruning\", \"pruning\", \"pruning\", \"pruning\", \"quantization\", \"quantization\", \"ranking\", \"ranking\", \"ranking\", \"ranking\", \"ranking\", \"ranking\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"real_world\", \"real_world\", \"real_world\", \"real_world\", \"real_world\", \"real_world\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommendation\", \"recommender_system\", \"recommender_system\", \"recommender_system\", \"recommender_system\", \"recurrent\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression\", \"regression_coefficient\", \"regression_coefficient\", \"regression_coefficient\", \"regression_coefficient\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret\", \"regret_bound\", \"regret_bound\", \"regret_bound\", \"regret_bound\", \"regret_bound\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"regularization\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"reinforcement_learning\", \"relational\", \"relational\", \"relational\", \"relational\", \"relational\", \"release\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"resampling\", \"resampling\", \"resampling\", \"resampling\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"reward\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"risk\", \"robot\", \"robot\", \"saddle_point\", \"safe\", \"safe\", \"safety\", \"satisfied\", \"satisfied\", \"satisfied\", \"scene\", \"scene\", \"scene\", \"scene\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"selection\", \"selection\", \"selection\", \"selection\", \"selection\", \"selection\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"sgd\", \"sgd\", \"shallow\", \"shallow\", \"short_term\", \"short_term\", \"short_term\", \"shot\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"shrinkage\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation_study\", \"simulation_study\", \"simulation_study\", \"simulation_study\", \"simulation_study\", \"simulation_study\", \"skill\", \"skill\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social\", \"social_medium\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source_domain\", \"source_target\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparsity\", \"sparsity\", \"sparsity\", \"sparsity\", \"sparsity\", \"sparsity\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"spectral_clustering\", \"spectral_clustering\", \"spectral_clustering\", \"spectral_clustering\", \"spectral_clustering\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state_art\", \"state_art\", \"state_art\", \"state_art\", \"state_art\", \"state_art\", \"stationary_point\", \"stationary_point\", \"stationary_point\", \"stationary_point\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"statistical\", \"step_size\", \"step_size\", \"step_size\", \"step_size\", \"step_size\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_gradient\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_optimization\", \"stochastic_optimization\", \"stock\", \"stock\", \"stock\", \"stored\", \"stored\", \"strong_convexity\", \"strong_convexity\", \"strongly_convex\", \"strongly_convex\", \"structured_sparsity\", \"structured_sparsity\", \"structured_sparsity\", \"student\", \"student\", \"student\", \"student\", \"student\", \"student\", \"subsampling\", \"subsampling\", \"subsampling\", \"subsampling\", \"subsampling\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace\", \"subspace_clustering\", \"subspace_clustering\", \"subspace_clustering\", \"suite\", \"suite\", \"support_vector\", \"support_vector\", \"support_vector\", \"support_vector\", \"support_vector\", \"support_vector\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"svm\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target_domain\", \"targeted\", \"team\", \"team\", \"term\", \"term\", \"term\", \"term\", \"term\", \"term\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text_classification\", \"textual\", \"textual\", \"thompson_sampling\", \"thompson_sampling\", \"time_series\", \"time_series\", \"time_series\", \"time_series\", \"time_series\", \"time_series\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"topic\", \"traffic\", \"traffic\", \"traffic\", \"traffic\", \"train\", \"train\", \"train\", \"train\", \"train\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"tree\", \"trend\", \"trend\", \"trend\", \"trend\", \"trend\", \"trial\", \"trial\", \"trial\", \"type\", \"type\", \"type\", \"type\", \"type\", \"type\", \"ucb\", \"ucb\", \"unbiased\", \"unbiased\", \"unbiased\", \"unbiased\", \"unbiased\", \"upper_lower\", \"upper_lower\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user\", \"user_item\", \"user_item\", \"user_item\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable_selection\", \"variable_selection\", \"variable_selection\", \"variable_selection\", \"variable_selection\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"varied\", \"varied\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vehicle\", \"vehicle\", \"video\", \"video\", \"video\", \"video\", \"video\", \"video\", \"visually\", \"visually\", \"wasserstein_distance\", \"weaker\", \"weaker\", \"weaker\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"worker\", \"worker\", \"worker\", \"worker\", \"x\", \"x\", \"x\", \"x\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5, 6]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el51941403784002212485923554437\", ldavis_el51941403784002212485923554437_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el51941403784002212485923554437\", ldavis_el51941403784002212485923554437_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el51941403784002212485923554437\", ldavis_el51941403784002212485923554437_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0      0.085819  0.045906       1        1  16.380466\n",
       "1     -0.067355 -0.057039       2        1  19.643486\n",
       "2      0.022425  0.064906       3        1  13.535698\n",
       "3      0.130090 -0.054458       4        1  19.251148\n",
       "4     -0.101227  0.066876       5        1  18.633482\n",
       "5     -0.069752 -0.066192       6        1  12.555710, topic_info=     Category         Freq                  Term        Total  loglift  \\\n",
       "term                                                                     \n",
       "201   Default  2029.000000            clustering  2029.000000  30.0000   \n",
       "555   Default  2019.000000             estimator  2019.000000  29.0000   \n",
       "791   Default  2815.000000                 image  2815.000000  28.0000   \n",
       "1349  Default  3116.000000        neural_network  3116.000000  27.0000   \n",
       "2776  Default  2037.000000         deep_learning  2037.000000  26.0000   \n",
       "1942  Default  1584.000000          architecture  1584.000000  25.0000   \n",
       "2777  Default  1454.000000           deep_neural  1454.000000  24.0000   \n",
       "477   Default  1136.000000               cluster  1136.000000  23.0000   \n",
       "385   Default  2688.000000                 error  2688.000000  22.0000   \n",
       "12    Default  2817.000000              estimate  2817.000000  21.0000   \n",
       "2025  Default  2392.000000              gradient  2392.000000  20.0000   \n",
       "90    Default  2684.000000            classifier  2684.000000  19.0000   \n",
       "2991  Default   767.000000  convolutional_neural   767.000000  18.0000   \n",
       "684   Default  1716.000000                  deep  1716.000000  17.0000   \n",
       "25    Default  3158.000000                 space  3158.000000  16.0000   \n",
       "125   Default  2524.000000                kernel  2524.000000  15.0000   \n",
       "166   Default  2289.000000            regression  2289.000000  14.0000   \n",
       "489   Default  2480.000000            estimation  2480.000000  13.0000   \n",
       "2422  Default  1351.000000                 layer  1351.000000  12.0000   \n",
       "486   Default  1914.000000                 bound  1914.000000  11.0000   \n",
       "387   Default  1654.000000                 label  1654.000000  10.0000   \n",
       "418   Default  1501.000000                metric  1501.000000   9.0000   \n",
       "366   Default  1975.000000                domain  1975.000000   8.0000   \n",
       "56    Default  2716.000000          optimization  2716.000000   7.0000   \n",
       "807   Default  1504.000000                  node  1504.000000   6.0000   \n",
       "444   Default  2495.000000                 point  2495.000000   5.0000   \n",
       "1838  Default  1480.000000                  user  1480.000000   4.0000   \n",
       "317   Default  3209.000000        representation  3209.000000   3.0000   \n",
       "2392  Default  1035.000000                attack  1035.000000   2.0000   \n",
       "686   Default  1911.000000               dynamic  1911.000000   1.0000   \n",
       "...       ...          ...                   ...          ...      ...   \n",
       "745    Topic6   293.075684          segmentation   450.165253   1.6458   \n",
       "576    Topic6   540.950806                 group  1094.125122   1.3706   \n",
       "1073   Topic6   571.259583                 multi  1191.084717   1.3402   \n",
       "2965   Topic6   271.546661              transfer   411.812469   1.6586   \n",
       "352    Topic6   755.501160                sparse  1964.674805   1.1193   \n",
       "2017   Topic6   239.855499           convolution   343.830658   1.7149   \n",
       "2172   Topic6   266.975159               labeled   406.946228   1.6535   \n",
       "383    Topic6   910.336914              datasets  3007.024170   0.8801   \n",
       "317    Topic6   894.088745        representation  3209.463379   0.7969   \n",
       "691    Topic6   669.203064              multiple  2142.157715   0.9115   \n",
       "2392   Topic6   435.666321                attack  1035.255371   1.2095   \n",
       "1235   Topic6   656.727356             state_art  2457.634521   0.7553   \n",
       "1666   Topic6   390.390839                source   914.699585   1.2235   \n",
       "734    Topic6   393.671631             detection   991.825439   1.1510   \n",
       "382    Topic6   551.542542               dataset  2236.812988   0.6749   \n",
       "559    Topic6   433.578888              instance  1279.081665   0.9932   \n",
       "883    Topic6   386.374878             component  1136.653320   0.9960   \n",
       "2271   Topic6   309.980194               spatial   617.555298   1.3857   \n",
       "353    Topic6   299.904877              sparsity   563.493530   1.4443   \n",
       "25     Topic6   507.596039                 space  3158.726562   0.2468   \n",
       "498    Topic6   481.330780              existing  2695.188477   0.3523   \n",
       "404    Topic6   485.393341              accuracy  2989.950195   0.2569   \n",
       "231    Topic6   417.565094                vector  1759.538574   0.6366   \n",
       "390    Topic6   443.022552                 novel  2388.223633   0.3903   \n",
       "388    Topic6   395.796997                 level  1490.614136   0.7490   \n",
       "873    Topic6   385.431702                target  1594.475342   0.6551   \n",
       "1074   Topic6   376.955017         paper_propose  1445.167236   0.7311   \n",
       "422    Topic6   344.245361        regularization  1171.705444   0.8501   \n",
       "239    Topic6   358.829926           demonstrate  2674.572266   0.0663   \n",
       "252    Topic6   357.491302               present  2763.137451   0.0300   \n",
       "\n",
       "      logprob  \n",
       "term           \n",
       "201   30.0000  \n",
       "555   29.0000  \n",
       "791   28.0000  \n",
       "1349  27.0000  \n",
       "2776  26.0000  \n",
       "1942  25.0000  \n",
       "2777  24.0000  \n",
       "477   23.0000  \n",
       "385   22.0000  \n",
       "12    21.0000  \n",
       "2025  20.0000  \n",
       "90    19.0000  \n",
       "2991  18.0000  \n",
       "684   17.0000  \n",
       "25    16.0000  \n",
       "125   15.0000  \n",
       "166   14.0000  \n",
       "489   13.0000  \n",
       "2422  12.0000  \n",
       "486   11.0000  \n",
       "387   10.0000  \n",
       "418    9.0000  \n",
       "366    8.0000  \n",
       "56     7.0000  \n",
       "807    6.0000  \n",
       "444    5.0000  \n",
       "1838   4.0000  \n",
       "317    3.0000  \n",
       "2392   2.0000  \n",
       "686    1.0000  \n",
       "...       ...  \n",
       "745   -6.0247  \n",
       "576   -5.4118  \n",
       "1073  -5.3573  \n",
       "2965  -6.1010  \n",
       "352   -5.0777  \n",
       "2017  -6.2251  \n",
       "2172  -6.1179  \n",
       "383   -4.8913  \n",
       "317   -4.9093  \n",
       "691   -5.1990  \n",
       "2392  -5.6282  \n",
       "1235  -5.2178  \n",
       "1666  -5.7380  \n",
       "734   -5.7296  \n",
       "382   -5.3924  \n",
       "559   -5.6330  \n",
       "883   -5.7483  \n",
       "2271  -5.9686  \n",
       "353   -6.0016  \n",
       "25    -5.4754  \n",
       "498   -5.5285  \n",
       "404   -5.5201  \n",
       "231   -5.6707  \n",
       "390   -5.6115  \n",
       "388   -5.7242  \n",
       "873   -5.7507  \n",
       "1074  -5.7730  \n",
       "422   -5.8637  \n",
       "239   -5.8223  \n",
       "252   -5.8260  \n",
       "\n",
       "[451 rows x 6 columns], token_table=      Topic      Freq                  Term\n",
       "term                                       \n",
       "404       1  0.172244              accuracy\n",
       "404       2  0.312714              accuracy\n",
       "404       3  0.114718              accuracy\n",
       "404       4  0.077928              accuracy\n",
       "404       5  0.159869              accuracy\n",
       "404       6  0.162210              accuracy\n",
       "2959      3  0.999117   activation_function\n",
       "3013      4  1.000278          actor_critic\n",
       "2985      4  0.999355                  admm\n",
       "2716      2  0.974947              adoption\n",
       "2716      6  0.023779              adoption\n",
       "1900      2  0.544971           adversarial\n",
       "1900      3  0.044038           adversarial\n",
       "1900      4  0.275238           adversarial\n",
       "1900      5  0.013211           adversarial\n",
       "1900      6  0.122206           adversarial\n",
       "1901      1  0.002739             adversary\n",
       "1901      2  0.753323             adversary\n",
       "1901      4  0.224627             adversary\n",
       "1901      5  0.008218             adversary\n",
       "1901      6  0.010957             adversary\n",
       "1524      1  0.005272                   age\n",
       "1524      2  0.021087                   age\n",
       "1524      3  0.005272                   age\n",
       "1524      5  0.964742                   age\n",
       "919       1  0.001210                 agent\n",
       "919       2  0.133118                 agent\n",
       "919       3  0.059903                 agent\n",
       "919       4  0.158531                 agent\n",
       "919       5  0.645621                 agent\n",
       "...     ...       ...                   ...\n",
       "231       5  0.171068                vector\n",
       "231       6  0.237562                vector\n",
       "2902      3  0.016649               vehicle\n",
       "2902      5  0.982320               vehicle\n",
       "1983      1  0.007247                 video\n",
       "1983      2  0.195666                 video\n",
       "1983      3  0.002416                 video\n",
       "1983      4  0.012078                 video\n",
       "1983      5  0.019325                 video\n",
       "1983      6  0.763339                 video\n",
       "1723      2  0.009687              visually\n",
       "1723      6  0.988057              visually\n",
       "2851      3  0.997756  wasserstein_distance\n",
       "760       1  0.811090                weaker\n",
       "760       2  0.154493                weaker\n",
       "760       6  0.038623                weaker\n",
       "1047      1  0.117035                weight\n",
       "1047      2  0.279356                weight\n",
       "1047      3  0.279356                weight\n",
       "1047      4  0.230542                weight\n",
       "1047      5  0.028818                weight\n",
       "1047      6  0.065281                weight\n",
       "2770      1  0.794773                worker\n",
       "2770      2  0.141378                worker\n",
       "2770      4  0.057315                worker\n",
       "2770      6  0.003821                worker\n",
       "2729      1  0.048550                     x\n",
       "2729      2  0.934579                     x\n",
       "2729      4  0.018206                     x\n",
       "2729      5  0.006069                     x\n",
       "\n",
       "[1698 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you set the lambda value to be lower, you can see more exclusive terms\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.gensim.prepare(filtered_lda, filterd_bow, dictionary, sort_topics = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
